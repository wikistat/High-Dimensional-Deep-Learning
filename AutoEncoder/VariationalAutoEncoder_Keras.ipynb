{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Dimensional & Deep Learning : Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variational autoencoder is an autoencoder that learns a latent variable model for its input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build a simple Variational Auto Encoder\n",
    "* Use Variational Auto Encoder for Number Generation \n",
    "* Use Variational Auto Encoder To anomaly detection\n",
    "* Write a Convolutional Variational Auto Encoder\n",
    "* Use the Keras Model APi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.preprocessing.image as kpi\n",
    "import tensorflow.keras.models as km\n",
    "import tensorflow.keras.layers as kl\n",
    "import tensorflow.keras.losses as kloss\n",
    "import tensorflow.keras.regularizers as kr\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.utils as ku\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "input_dim = np.prod(x_train.shape[1:])\n",
    "n_train = x_train.shape[0]\n",
    "n_test = x_test.shape[0]\n",
    "x_train = x_train.reshape((n_train, input_dim))\n",
    "x_test = x_test.reshape((n_test, input_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous TP on image classification of the autoencoder notebook we have used the `Sequential` method to build model.\n",
    "\n",
    "Sequential Method have limits when the architecture we want is not *linear* or when we want to build a layer on top on two different entries.\n",
    "\n",
    "The `Model` API can sometimes be less intuitive but is much more flexible than the `Sequential` method. We will use it all along this TP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## A simple Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "\n",
    "batch_size=100\n",
    "intermediate_dim = 512\n",
    "latent_dim = 2\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first build the encoder part. <br>\n",
    "It is first composed of  a `Dense` layer with 512 neurons. <br>\n",
    "Two `Dense` layer are then added on **top of the same layer**. These two layers will produce the two variable *z_mean* and  *z_log_var* in the latent space.\n",
    "\n",
    "Note that we define each layer as a function of an input which is the output of the layer he follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build encoder model\n",
    "inputs = kl.Input(shape=(784,), name='encoder_input')\n",
    "x = kl.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = kl.Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = kl.Dense(latent_dim, name='z_log_var')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Â The stochastic latent variable\n",
    "\n",
    "We use the reparametrization trick to define a random variable z that is conditioned on the input image x as follows:\n",
    "\n",
    "$$ z \\sim \\mathcal{N}(\\mu_z(x), \\sigma_z(x)) $$\n",
    "\n",
    "<img src=\"image/vae_3.svg\" width=\"600px\" />\n",
    "\n",
    "\n",
    "\n",
    "The reparametrization tricks defines $z$ has follows:\n",
    "\n",
    "$$ z = \\mu_z(x) + \\sigma_z(x) \\cdot \\epsilon$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$ \\epsilon \\sim \\mathcal{N}(0, 1) $$\n",
    "\n",
    "This way the dependency to between $z$ and $x$ is deterministic and differentiable. The randomness of $z$ only stems from $\\epsilon$ only for a given $x$.\n",
    "\n",
    "Note that in practice the output of the encoder network parameterizes $log(\\sigma^2_z(x)$ instead of $\\sigma_z(x)$. Taking the exponential of $log(\\sigma^2_z(x)$ ensures the positivity of the standard deviation from the raw output of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim))\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "z = kl.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have defined all the layer we need to build the encoder part of the vae. <br> \n",
    "We now define the model, with the `Model`method. For that we just have to specify the input layer and the output we want (here, it's the latent variable z). The model is then build automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate encoder model\n",
    "\n",
    "encoder = km.Model(inputs, z, name='encoder')\n",
    "encoder.summary()\n",
    "#ku.plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder \n",
    "\n",
    "The decoder take as an input the a vector z (which is a sample of the latent distribution define by the encoder). \n",
    "it is then compose of 2 Dense layers with the following caracteristics : \n",
    "\n",
    "* 512 neurons, relu activation\n",
    "* 784 neurons (input_shape), sigmoid activation\n",
    "\n",
    "**Exercise** build this simple model using the Model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/decoder_vae.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vae\n",
    "\n",
    "We now associate the two model to define our Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs))\n",
    "vae = km.Model(inputs, outputs, name='vae_mlp')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reconstruction_loss = kloss.binary_crossentropy(inputs,\n",
    "                                              outputs)\n",
    "\n",
    "reconstruction_loss *= 784\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit(x_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display images result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_decoded_vae = vae.predict(x_test, batch_size= batch_size)\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(x_test_decoded_vae[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of latent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "for i in range(10):\n",
    "    x_test_encoded_i = x_test_encoded[y_test==i]\n",
    "    plt.scatter(x_test_encoded_i[:, 0], x_test_encoded_i[:, 1], label=i)\n",
    "ax.grid(False)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Generate a image number from two random latent varianle using the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load solutions/generate_single_sample.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View of VAE Manifolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 15  # figure with 15x15 panels\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "grid_x = sc.stats.norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = sc.stats.norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = decoder.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection\n",
    "\n",
    "In this part we'll se how variational autoencoder can be used to anomaly detections.\n",
    "\n",
    "We will consider that 9 images are outliers. \n",
    "\n",
    "We will generate four datasets from both train and test dataset, train and test without 9 images and train and test with only 9 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_i = 9\n",
    "x_train_normal = x_train[y_train!=outlier_i]\n",
    "n_train = x_train_normal.shape[0]-x_train_normal.shape[0]%100\n",
    "x_train_normal = x_train_normal[:n_train]\n",
    "x_test_normal =  x_test[y_test!=outlier_i]\n",
    "n_test = x_test_normal.shape[0]-x_test_normal.shape[0]%100\n",
    "x_test_normal = x_test_normal[:n_test]\n",
    "\n",
    "x_train_outliers = x_train[y_train==outlier_i]\n",
    "n_train = x_train_outliers.shape[0]-x_train_outliers.shape[0]%100\n",
    "x_train_outliers = x_train_outliers[:n_train]\n",
    "x_test_outliers =  x_test[y_test==outlier_i]\n",
    "n_test = x_test_outliers.shape[0]-x_test_outliers.shape[0]%100\n",
    "x_test_outliers = x_test_outliers[:n_test]\n",
    "\n",
    "x_train_normal.shape, x_train_outliers.shape, x_test_normal.shape, x_test_outliers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then build a VAE and we learn weight only on train dataset without 9 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "inputs = kl.Input(shape=(784,), name='encoder_input')\n",
    "x = kl.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = kl.Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = kl.Dense(latent_dim, name='z_log_var')(x)\n",
    "z = kl.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "encoder_ad = km.Model(inputs, z, name='encoder')\n",
    "\n",
    "# decoder\n",
    "latent_inputs = kl.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = kl.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = kl.Dense(784, activation='sigmoid')(x)\n",
    "decoder_ad = km.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "# vae\n",
    "outputs = decoder_ad(encoder_ad(inputs))\n",
    "vae_ad = km.Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "reconstruction_loss = kloss.binary_crossentropy(inputs,outputs)\n",
    "reconstruction_loss *= 784\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae_ad.add_loss(vae_loss)\n",
    "vae_ad.compile(optimizer='adam')\n",
    "\n",
    "vae_ad.fit(x_train_normal,epochs=epochs, batch_size=batch_size, validation_data=(x_test_normal, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display decoded image\n",
    "\n",
    "Lets know try to use our VAE on test dataset with both know numbers (0 to 8) and with outliers (9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_decoded_vae = vae_ad.predict(x_test_normal, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_normal[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(x_test_decoded_vae[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_decoded_vae = vae_ad.predict(x_test_outliers, batch_size=batch_size)\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test_outliers[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(x_test_decoded_vae[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : What can you say about the decoded images in both cases? Is it normal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Distribution\n",
    "\n",
    "Let's know this the error distrubtion between images and their reconstructed images using vae for three type of images:\n",
    "\n",
    "* Images of know number (0 to 8)\n",
    "* Images of outlier (9)\n",
    "* Completly randomly generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_normal_decoded = vae_ad.predict(x_test_normal, batch_size=batch_size)\n",
    "error_normal = np.linalg.norm(x_test_normal-x_test_normal_decoded, axis=1)\n",
    "\n",
    "x_test_outliers_decoded = vae_ad.predict(x_test_outliers, batch_size =batch_size)\n",
    "error_outliers = np.linalg.norm(x_test_outliers-x_test_outliers_decoded, axis=1)\n",
    "\n",
    "x_random = np.random.uniform(size=(1000, 784),low=0.0, high=1.0)\n",
    "x_random_decoded =  vae_ad.predict(x_random, batch_size=batch_size)\n",
    "error_random = np.linalg.norm(x_random-x_random_decoded, axis=1)\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(9,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sb.distplot(error_normal, ax=ax, label=\"Normal\")\n",
    "sb.distplot(error_outliers, ax=ax, label=\"Outliers\")\n",
    "sb.distplot(error_random , ax=ax, label=\"Random\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What can you say about the error reconstruction of the different case? Wah does it say about the performance of VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Network\n",
    "\n",
    "**Exercise** You've seen how to build VAE and how to use it to generate new images and to detect anomaly. The VAE used so far only use Dense layer. \n",
    "\n",
    "Use CNN layer to build a convolutional VAE and test the different application (generate images and detect anomaly)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
