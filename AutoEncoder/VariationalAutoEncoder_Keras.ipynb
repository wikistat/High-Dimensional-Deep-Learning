{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wikistat/High-Dimensional-Deep-Learning/blob/master/AutoEncoder/VariationalAutoEncoder_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files & Data (Google Colab)\n",
    "\n",
    "If you're running this notebook on Google colab, you do not have access to the `solutions` folder you get by cloning the repository locally. \n",
    "\n",
    "The following lines will allow you to build the folders and the files you need for this TP.\n",
    "\n",
    "**WARNING 1** Do not run this line localy.\n",
    "**WARNING 2** The magic command `%load` does not work work on google colab, you will have to copy-paste the solution on the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir image\n",
    "! wget . https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/vae_mlp_decoder.png\n",
    "! wget . https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/vae_mlp_vae.png\n",
    "! wget image https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/image/vae_2.svg\n",
    "! wget image https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/image/vae_3.svg\n",
    "! mkdir solutions\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/compare_sparsity_decoded_imgs.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/compare_sparsity_encoded_imgs.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/convolutional_autoencoder.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/decoded_images_both_method.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/decoder_vae.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/generate_single_sample.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/simple_autoencoder.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/vae.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/train_outlier_vae.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/error_distribution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Dimensional & Deep Learning : Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variational autoencoder is an autoencoder that learns a latent variable model for its input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build a simple Variational Auto Encoder\n",
    "* Use Variational Auto Encoder for Number Generation \n",
    "* Use Variational Auto Encoder To anomaly detection\n",
    "* Write a Convolutional Variational Auto Encoder\n",
    "* Use the Keras Model APi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.preprocessing.image as kpi\n",
    "import tensorflow.keras.models as km\n",
    "import tensorflow.keras.layers as kl\n",
    "import tensorflow.keras.losses as kloss\n",
    "import tensorflow.keras.regularizers as kr\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.utils as ku\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "input_dim = np.prod(x_train.shape[1:])\n",
    "n_train = x_train.shape[0]\n",
    "n_test = x_test.shape[0]\n",
    "x_train = x_train.reshape((n_train, input_dim))\n",
    "x_test = x_test.reshape((n_test, input_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous TP on image classification of the autoencoder notebook we have used the `Sequential` method to build model.\n",
    "\n",
    "Sequential Method have limits when the architecture we want is not *linear* or when we want to build a layer on top on two different entries.\n",
    "\n",
    "The `Model` API can sometimes be less intuitive but is much more flexible than the `Sequential` method. We will use it all along this TP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## A simple Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "n_input = 784\n",
    "batch_size=100\n",
    "intermediate_dim = 512\n",
    "latent_dim = 2\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first build the encoder part. <br>\n",
    "It is first composed of  a `Dense` layer with 512 neurons. <br>\n",
    "Two `Dense` layer are then added on **top of the same layer**. These two layers will produce the two variable *z_mean* and  *z_log_var* in the latent space.\n",
    "\n",
    "Note that we define each layer as a function of an input which is the output of the layer it follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs layer\n",
    "inputs = kl.Input(shape=(784,), name='encoder_input')\n",
    "# Dense layer from input layer\n",
    "x = kl.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "# Two dense layer that takes input from the same layer x\n",
    "z_mean = kl.Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = kl.Dense(latent_dim, name='z_log_var')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The stochastic latent variable\n",
    "\n",
    "We use the reparametrization trick to define a random variable z that is conditioned on the input image x as follows:\n",
    "\n",
    "$$ q(z/X) \\sim \\mathcal{N}(\\mu_z(x), \\sigma_z(x)) $$\n",
    "\n",
    "<img src=\"image/vae_3.svg\" width=\"600px\" />\n",
    "\n",
    "\n",
    "\n",
    "The reparametrization tricks defines $z$ has follows:\n",
    "\n",
    "$$ q(z/X) = \\mu_z(x) + \\sigma_z(x) \\cdot \\epsilon$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$ \\epsilon \\sim \\mathcal{N}(0, 1) $$\n",
    "\n",
    "This way the dependency to between $z$ and $x$ is deterministic and differentiable. The randomness of $z$ only stems from $\\epsilon$ only for a given $x$.\n",
    "\n",
    "Note that in practice the output of the encoder network parameterizes $log(\\sigma^2_z(x))$ instead of $\\sigma_z(x)$. <br>\n",
    "Taking the exponential of $log(\\sigma^2_z(x)$ ensures the positivity of the standard deviation from the raw output of the network:\n",
    "\n",
    "\n",
    "Let's first define a function that takes as an inputs the output of the `Z_mean`, and `Z_log_var` previous layer and generate a sample from this inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim))\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a keras layer from this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "z = kl.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have defined all the layer we need to build the encoder part of the vae. <br> \n",
    "We now define the model, with the `Model`method. For that we just have to specify the input layer and the output we want (here, it's the latent variable z). The model is then build automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate encoder model\n",
    "\n",
    "encoder = km.Model(inputs, z, name='encoder')\n",
    "encoder.summary()\n",
    "#ku.plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder \n",
    "\n",
    "The decoder take as an input the a vector z (which is a sample of the latent distribution define by the encoder). \n",
    "it is then compose of 2 Dense layers with the following caracteristics : \n",
    "\n",
    "* 512 neurons, relu activation\n",
    "* 784 neurons (input_shape), sigmoid activation\n",
    "\n",
    "**Exercise** build this simple decoder model using the Model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/decoder_vae.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vae\n",
    "\n",
    "We now associate the encoder and the decoder to define our Variational Autoencoder.\n",
    "\n",
    "**Exercise** build this VAE model using the Model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/vae.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement now the vae loss function  as described in the course\n",
    "\n",
    "$$VAE_{loss} = l(x,\\hat{x}) + KL(q(z/X),p(z))$$\n",
    "\n",
    "$l$ can be any loss function betwen the original image $x$ and the reconstructed image $\\hat{x}$. Here we use the binary crossentropy. \n",
    "\n",
    "\n",
    "$$ q(z/X) \\sim \\mathcal{N}(\\mu_z(x), \\sigma_z(x)), $$\n",
    "as described below. $p(z)$ is the latent distribution. The easiest choice would to represent it would be : \n",
    "$$p(z)\\sim \\mathcal{N}(0,1)$$\n",
    "\n",
    "\n",
    "$\n",
    "KL(Q || P) = \\frac{1}{2}\\left[\\log\\frac{|\\Sigma_p|}{|\\Sigma_q|} - d + \\text{tr} \\{ \\Sigma_p^{-1}\\Sigma_q \\} + (\\mu_p - \\mu_q)^T \\Sigma_p^{-1}(\\mu_p - \\mu_q)\\right].\n",
    "$\n",
    "\n",
    "which with our value lead to\n",
    "\n",
    "$\n",
    "KL(q(z/X) || p(z)) = \\frac{1}{2}\\left[-\\log|\\sigma_z(x)| - d + \\text{tr} \\{\\sigma_z(x) \\} +\\mu_z(x)^T \\mu_z(x)\\right].\n",
    "$\n",
    "\n",
    "which can be computed as : \n",
    "\n",
    "$KL(q(z/X) || p(z)) = \\frac{1}{2} \\, \\sum_d \\left( \\sigma_z(x) + \\mu_z^2(x) - 1 - \\log \\sigma_z(x) \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss = kloss.binary_crossentropy(inputs,\n",
    "                                              outputs)\n",
    "\n",
    "reconstruction_loss *= 784\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit(x_train,\n",
    "                epochs=40,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display images result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_decoded_vae = vae.predict(x_test, batch_size= batch_size)\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(x_test_decoded_vae[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of latent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "for i in range(10):\n",
    "    x_test_encoded_i = x_test_encoded[y_test==i]\n",
    "    plt.scatter(x_test_encoded_i[:, 0], x_test_encoded_i[:, 1], label=i)\n",
    "ax.grid(False)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Generate a image number from two random latent varianle using the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/generate_single_sample.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View of VAE Manifolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 15  # figure with 15x15 panels\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "grid_x = sc.stats.norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = sc.stats.norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = decoder.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection\n",
    "\n",
    "In this part we'll se how variational autoencoder can be used to anomaly detections.\n",
    "\n",
    "We will consider that 9 images are outliers. \n",
    "\n",
    "We will generate four datasets from both train and test dataset, train and test without 9 images and train and test with only 9 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_i = 9\n",
    "x_train_normal = x_train[y_train!=outlier_i]\n",
    "n_train = x_train_normal.shape[0]-x_train_normal.shape[0]%100\n",
    "x_train_normal = x_train_normal[:n_train]\n",
    "x_test_normal =  x_test[y_test!=outlier_i]\n",
    "n_test = x_test_normal.shape[0]-x_test_normal.shape[0]%100\n",
    "x_test_normal = x_test_normal[:n_test]\n",
    "\n",
    "x_train_outliers = x_train[y_train==outlier_i]\n",
    "n_train = x_train_outliers.shape[0]-x_train_outliers.shape[0]%100\n",
    "x_train_outliers = x_train_outliers[:n_train]\n",
    "x_test_outliers =  x_test[y_test==outlier_i]\n",
    "n_test = x_test_outliers.shape[0]-x_test_outliers.shape[0]%100\n",
    "x_test_outliers = x_test_outliers[:n_test]\n",
    "\n",
    "x_train_normal.shape, x_train_outliers.shape, x_test_normal.shape, x_test_outliers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exervise** Build a VAE as we did above on this noteboo and learn weight only on train dataset without 9 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/train_outlier_vae.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display decoded image\n",
    "\n",
    "Lets know try to use our VAE on test dataset with both know numbers (0 to 8) and with outliers (9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_decoded_vae = vae_ad.predict(x_test_normal, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_normal[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(x_test_decoded_vae[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_decoded_vae = vae_ad.predict(x_test_outliers, batch_size=batch_size)\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test_outliers[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(x_test_decoded_vae[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : What can you say about the decoded images in both cases? Is it normal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Distribution\n",
    "\n",
    "To evaluate how the detection of 9 image will work, let us check the distribution of the different l2 errors between the original image and their reconstructed image for three type if images:\n",
    "\n",
    "* Images of know number (0 to 8)\n",
    "* Images of outlier (9)\n",
    "* Completly randomly generated images\n",
    "\n",
    "**Exercise** Generate these distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/error_distribution.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(9,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sb.distplot(error_normal, ax=ax, label=\"Normal\")\n",
    "sb.distplot(error_outliers, ax=ax, label=\"Outliers\")\n",
    "sb.distplot(error_random , ax=ax, label=\"Random\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What can you say about the error reconstruction of the different case? Wah does it say about the performance of VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Network\n",
    "\n",
    "**Exercise** You've seen how to build VAE and how to use it to generate new images and to detect anomaly. The VAE used so far only use Dense layer. \n",
    "\n",
    "Use CNN layer to build a convolutional VAE and test the different application (generate images and detect anomaly)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
