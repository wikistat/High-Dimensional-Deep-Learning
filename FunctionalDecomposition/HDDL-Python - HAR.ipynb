{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Activity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Summary\n",
    "\n",
    "The data we will study all along this notebook are public data, which were acquired and described by [Anguita et al. (2013)](). They are available on the [bucket](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) of Irvine California University. They represent usecases of Human Activity Recognition from signal recordings (gyroscope, accelerometer) obtained with a smartphone. The data are analyzed to illustrate the main common steps in data science applicable to sampled physical signals. Visualization of raw signals to evaluate the difficulties posed by this type of data; exploration ([principal component analysis](http://wikistat.fr/pdf/st-m-explo-acp.pdf), [discriminant factor analysis](http://wikistat.fr/pdf/st-m-explo-acp.pdf)) of the transformed data (*features*) calculated from the signals; prediction of activity from the features data by most linear methods including: [logistic regression](http://wikistat.fr/pdf/st-m-app-rlogit.pdf), linear and nonlinear [SVM](http://wikistat.fr/pdf/st-m-app-svm.pdf),  prediction of the activity from the raw signals by elementary [neural network](http://wikistat.fr/pdf/st-m-app-rn.pdf) and  [convolutional networks](http://wikistat.fr/pdf/st-m-app-rn.pdf) (deep learning). This notebook shows the very good (96%) prediction of elementary linear methods on the features  data and, to save cost (for the embedded battery) transformations, similar accuracies are obtained by a convolutional network on the raw signals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Objectives \n",
    "\n",
    "The objective is to recognize the activity of an individual from a set of signals recorded on a smartphone from the embedded gyroscope and accelerometer. A learning database has been built experimentally. A set of persons  performed a determined activity for a predefined period of time while signals were recorded. The data come from the community that aims to recognize human activities (Human activity recognition, HAR). See the [paper](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-11.pdf) on a symposium in 2013. The analysis of data associated with real-time activity identification is not discussed.\n",
    "\n",
    "The available public data was acquired, described and partly analyzed by [Anguita et al. (2013)](https://www.icephd.org/sites/default/files/IWAAL2012.pdf). They are available on the University California Irvine (UCI) [repository](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) dedicated to machine learning.\n",
    "\n",
    "The archive contains the raw data: accelerations sampled at 64 htz during 2s. The accelerations in x, y, and z (body_acc), each contains 128 columns, those by subtracting the natural gravity (total_acc) as well as the angular accelerations in x, y, and z obtained from the gyroscope (body_gyro). The choice of a power of 2 for the sampling frequency allows the efficient execution of Fourier transform or wavelet transform algorithms.\n",
    "\n",
    "\n",
    "The *features data* have been built from the *a priori* knowledge on the behaviour of the different activities we want to study. We will see that it is easy to achieve high performances for the classification problem using these features data. \n",
    "\n",
    "\n",
    "The objective of this TP is to try to achieve the same performances directly from the original data (the raw signals) using different tools : \n",
    "\n",
    "* Signal decomposition in different basis (Wavelet, Fourier)\n",
    "* Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The data set \n",
    "\n",
    "Each registration is labeled with **6 activities**: standing, sitting, lying, walking, walking upstairs or walking downstairs. Each dataset (the raw data and the features data) is splitted into a learning sample and a test sample. The test sample is only used to evaluate and compare the predictive qualities of the main methods.  This is a problem of **supervised classification** (6 classes) with $7352$  samples for learning and  $2947$ for testing.\n",
    "\n",
    "\n",
    "The dataset has been donwloaded and is available on this github repository at the following path : `data/HumanActivityRecognition/` and follow this organisation :\n",
    "\n",
    "```\n",
    "train\n",
    "└───Inertial Signals/\n",
    "|   |   body_acc_x_train.txt\n",
    "|   |   body_acc_y_train.txt\n",
    "|   |   body_acc_z_train.txt\n",
    "|   |   body_gyro_x_train.txt\n",
    "|   |   body_gyro_y_train.txt\n",
    "|   |   body_gyro_z_train.txt\n",
    "|   |   total_acc_x_train.txt\n",
    "|   |   total_acc_y_train.txt\n",
    "|   |   total_acc_z_train.txt\n",
    "|   X_train.txt\n",
    "|   y_train.txt\n",
    "test\n",
    "└───Inertial Signals/\n",
    "|   |   body_acc_x_test.txt\n",
    "|   |   body_acc_y_test.txt\n",
    "|   |   body_acc_z_test.txt\n",
    "|   |   body_gyro_x_test.txt\n",
    "|   |   body_gyro_y_test.txt\n",
    "|   |   body_gyro_z_test.txt\n",
    "|   |   total_acc_x_test.txt\n",
    "|   |   total_acc_y_test.txt\n",
    "|   |   total_acc_z_test.txt\n",
    "|   X_test.txt\n",
    "|   y_test.txt\n",
    "features.txt\n",
    "```\n",
    "\n",
    "The `train` and `test` datasets are composed respectively of $10299$ and $2947$ individuals. In each folder you will find :\n",
    "\n",
    "* The `Inertial Signal` folder that contains the original data for each individual :\n",
    "    * Triaxial acceleration from the accelerometer (total acceleration) in x, y and z,\n",
    "    * The estimated body acceleration in x, y and z,\n",
    "    * Triaxial Angular velocity from the gyroscope in x, y and z.\n",
    "    \n",
    "    \n",
    "    \n",
    "* The `X_*.txt` files that contains a 561 features vector for each individual among the following variable\n",
    "\n",
    "Name|Signification\n",
    "-|-\n",
    "mean | Mean value\n",
    "std | Standard deviation\n",
    "mad | Median absolute value\n",
    "max | Largest values in array\n",
    "min | Smallest value in array\n",
    "sma | Signal magnitude area\n",
    "energy | Average sum of the squares\n",
    "iqr | Interquartile range\n",
    "entropy | Signal Entropy\n",
    "arCoeff | Autorregresion coefficients\n",
    "correlation | Correlation coefficient\n",
    "maxFreqInd | Largest frequency component\n",
    "meanFreq | Frequency signal weighted average\n",
    "skewness | Frequency signal Skewness\n",
    "kurtosis | Frequency signal Kurtosis\n",
    "energyBand | Energy of a frequency interval\n",
    "angle | Angle between two vectors\n",
    "\n",
    "* The `y_*.txt` files that contains the true activity label among the 6 possibilities :\n",
    "    * WALKING,\n",
    "    * WALKING UPSTAIRS,\n",
    "    * WALKING DOWNSTAIRS,\n",
    "    * SITTING,\n",
    "    * STANDING,\n",
    "    * LAYING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Workflow \n",
    "\n",
    "A first visualization and exploration of the raw signals shows that they are difficult to analyze; the activity classes are indeed poorly characterized. The main reason is the lack of synchronization of the beginning of the activity; the phase shift of the signals then appears as a noise or artefact very detrimental to the good discrimination of the activities on the basis of the usual Euclidean distance. This is the reason why, [Anguita et al. (2013)](https://www.icephd.org/sites/default/files/IWAAL2012.pdf) propose to compute a set of transformations or characteristics (*features*) of the signals: variance, correlations, entropy, Fourier decomposition ... These are then $ p = 561 $ variables that are considered and explored in Section 3. The [principal component analysis](http://wikistat.fr/pdf/st-m-explo-acp. pdf) and especially the [discriminant factorial analysis](http://wikistat.fr/pdf/st-m-explo-acp.pdf) show the good discriminating qualities of these features data obtained from an expert's knowledge on signal processing. Section 4 exploits these features variables and shows that elementary statistical models, such as linear models (logistic regression, discriminant analysis) or a traditional support vector machine (SVM) algorithm using a simple linear kernel, lead to excellent forecasts, which is not the case for sophisticated nonlinear algorithms (*random forest, gradient boosting*).\n",
    "\n",
    "However, having sophisticated transformations (such as Fourier transform) continuously calculated is not a viable solution for the battery of a connected embedded object. The candidate algorithm should  be able to produce an integrated solution  in a cicuit, as it is the case for chips dedicated to facial recognition. This is the purpose of section 5: to demonstrate the feasibility of a solution based only on raw signals; solution implementing a neural network integrating  convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Software Environment\n",
    "To be executed, this notebook (*jupyter notebook*) requires the installation of Python3 via for example the site [Anaconda](https://conda.io/docs/user-guide/install/download.html). The statistical exploration and learning algorithms used are available in the [`Scikit-learn` library](http://scikit-learn.org/stable/) while a basic approach to deep network learning of neurons with convolutional layer requires the installation of the library [`Keras`](https://keras.io/) which drives that of [`TensorFlow`](https://www.tensorflow.org/).\n",
    "\n",
    "**Notes:**\n",
    "- this notebook was built and tested on Ubuntu Mate 16.04 (Python 3.6) but its use on Windows or Mac OS is  not be a problem once the environment is properly installed.\n",
    "- the `conda` command installs the` Keras` environment without difficulty, including `TensorFlow`;\n",
    "the neural networks considered remain of simple structure, a GPU card is not essential for their learning unless the user wishes to improve the optimizations and choice of the architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import collections\n",
    "\n",
    "# Custom function that will allow to load data\n",
    "import utils.load as ul\n",
    "# Custom function that will allow to display some results\n",
    "import utils.illustration as uil\n",
    "\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set()\n",
    "sb.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "import sklearn.decomposition as sdec\n",
    "import  sklearn.preprocessing as sprep\n",
    "import sklearn.discriminant_analysis as sda\n",
    "\n",
    "import pywt\n",
    "from pywt import wavedec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some static data that will be used all along this TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMAP = plt.get_cmap(\"Set1\")\n",
    "ACTIVITY_DIC = {1 : \"WALKING\",\n",
    "2 : \"WALKING UPSTAIRS\",\n",
    "3 : \"WALKING DOWNSTAIRS\",\n",
    "4 : \"SITTING\",\n",
    "5 : \"STANDING\",\n",
    "6 : \"LAYING\"}\n",
    "COLOR_DIC = {v:CMAP(k-2) if v!=\"WALKING\" else CMAP(11) for k,v in ACTIVITY_DIC.items()}\n",
    "SIGNALS = [ \"body_acc_x\", \"body_acc_y\", \"body_acc_z\", \"body_gyro_x\", \"body_gyro_y\", \"body_gyro_z\", \"total_acc_x\", \"total_acc_y\", \"total_acc_z\"]\n",
    "LABELS = [ACTIVITY_DIC[c] for c in range(1,7)]\n",
    "COLOR_LIST = [COLOR_DIC[l] for l in LABELS]\n",
    "DATA_PATH = \"../data/HumanActivityRecognition/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "\n",
    "##  The features data\n",
    "\n",
    "The data set contains two `train` and` test` files of the 561 characteristics (*features*) variables computed in the time and frequency domains by transformation of the raw signals.\n",
    "We will first have a look at these features data. We first read and vizualize the data. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrainFeatures=ul.my_read_csv(DATA_PATH+\"train/X_train.txt\")\n",
    "XTestFeatures=ul.my_read_csv(DATA_PATH+\"test/X_test.txt\")\n",
    "ytrain=ul.my_read_csv(DATA_PATH+\"train/y_train.txt\")[0]\n",
    "ytrain_label = [ACTIVITY_DIC[y] for y in ytrain]\n",
    "ytest=ul.my_read_csv(DATA_PATH+\"test/y_test.txt\")[0]\n",
    "ytest_label = [ACTIVITY_DIC[y] for y in ytest]\n",
    "print(\"X Train data dimensions %d X %d\" %(XTrainFeatures.shape))\n",
    "print(\"X Test data dimensions %d X %d\" %(XTestFeatures.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrainFeatures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the distributions of the different label. We can see that the data are well balanced in both train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "\n",
    "ytrain_vc = collections.Counter(ytrain_label)\n",
    "labels = ytrain_vc.keys()\n",
    "colors = [COLOR_DIC[x] for x in labels]\n",
    "sizes = [ytrain_vc[c] for c in labels]\n",
    "ax.pie(sizes, labels=labels,colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "ax.axis('equal')\n",
    "ax.set_title(\"Train\", fontsize=20)\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ytest_vc = collections.Counter(ytest_label)\n",
    "labels = ytest_vc.keys()\n",
    "sizes = [ytest_vc[c] for c in labels]\n",
    "colors = [COLOR_DIC[x] for x in labels]\n",
    "ax.pie(sizes, labels=labels,colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "ax.axis('equal')\n",
    "ax.set_title(\"Test\", fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration \n",
    "\n",
    "The following code allows to display the results of the PCA on the features data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sdec.PCA()\n",
    "X_r = pca.fit_transform(XTrainFeatures)\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "uil.plot_variance_acp(fig, pca, X_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=[COLOR_DIC[y] for y in ytrain_label]\n",
    "markersizes = [20 for y in ytrain]\n",
    "\n",
    "fig = plt.figure(figsize= (15,15))\n",
    "count = 0\n",
    "for nbc, nbc2,count in [(1,2,1), (2,3,2), (3,4,3), (1,3,4), (2,4,5), (1,4,7)] :\n",
    "    ax = fig.add_subplot(3,3,count)\n",
    "    uil.plot_pca(ax, X_r, pca, nbc, nbc2, colors, markersizes)\n",
    "\n",
    "#Build legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [Line2D([0], [0], color=COLOR_DIC[act],marker=\".\", linestyle=None, markersize=25, label=act)for act in ACTIVITY_DIC.values()]\n",
    "plt.legend(handles=legend_elements,loc='upper right', bbox_to_anchor=(3, 1.6),fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** How is the PCA performing? How many components, among 561, would we need to describe the data?\n",
    "\n",
    "**Q** Comment the separation you can see on the first axis\n",
    "\n",
    "**Q** What can you say about the shape of the cloud?\n",
    "\n",
    "**Q** What can you say about classes separation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised classification  with the [logistic regression](http://wikistat.fr/pdf/st-m-app-rlogit.pdf)\n",
    "\n",
    "####  Principle \n",
    "\n",
    "The `Logistic Regression` is a very simple and classical statistical method for supervised classification,  but it is very effective on these features data. Logistic regression is suitable for predicting a binary variable. In the multiclass case, the logistic function of the `Scikit-learn` library estimates *by default* ** one model per class **: one class against the others.\n",
    "\n",
    "The probability that one individual belongs to some class is modeled using a linear combination of the explanatory variables (features). To transform a real-valued linear combination  into a probability with values in the interval $ [0, 1] $, a sigmoidal function is applied. This gives :\n",
    "$$P(y_i=1/X)=\\frac{e^{Xb}}{1+e^{Xb}}$$\n",
    "or equivalently\n",
    "$$\\log\\frac{P(y_i=1/X)}{1-P(y_i=1/X)}=Xb.$$\n",
    "\n",
    "The class affected to one individual is the one corresponding to the highest predicted probability. \n",
    "\n",
    "####  Estimation  of the model without optimization\n",
    "\n",
    "The model is estimated without trying to refine the values of certain parameters (penalization). \n",
    "\n",
    "**NB** If you want to go further on the analysis of the features data, and study the performances of different algorithms such as  SVM,  discriminant analysis, $k$nearest neighbours, random forests, neural networks...see the corresponding notebook at `../data/HumanActivityRecognition/former_notebook`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "ts = time.time()\n",
    "method = LogisticRegression()\n",
    "method.fit(XTrainFeatures,ytrain)\n",
    "score = method.score(XTestFeatures, ytest)\n",
    "ypred = method.predict(XTestFeatures)\n",
    "ypred_label = np.array([ACTIVITY_DIC[y] for y in ypred])\n",
    "te = time.time()\n",
    "\n",
    "print(\"Score : %f, time running : %d secondes\" %(score, te-ts))\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sb.heatmap(pd.crosstab(np.array(ytest_label), ypred_label, rownames=['True'], colnames=['Pred']), annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Comments the quality of the results. Are they coherent with the exploration stage?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Raw Signals \n",
    "\n",
    "We will now try to achieve on the original signal data the same performance for the  classification as the one we got on the features data. We first read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multidimensional Data\n",
    "XTrainSignals, XTestSignals = ul.load_signals(DATA_PATH, \"train\", SIGNALS), ul.load_signals(DATA_PATH, \"test\", SIGNALS)\n",
    "N_train, N_dim, N_signaux  = XTrainSignals.shape\n",
    "N_test, _, _  = XTestSignals.shape\n",
    "print(\"X Train data dimensions %d X %d X %d\" %(XTrainSignals.shape))\n",
    "print(\"X Test data dimensions %d X %d X %d\" %(XTestSignals.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the studies we will produce on the data require the data to be 1-dimensional. This is  why we produce *flatten* data that will gather in a single vector the $9$ signals per individual and produce 1D vectors of size 128X9 = 1152. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten_data\n",
    "XTrainFlatten = XTrainSignals.reshape((N_train, N_dim*N_signaux), order=\"F\")\n",
    "XTestFlatten = XTestSignals.reshape((N_test, N_dim*N_signaux), order=\"F\")\n",
    "print(\"X Train data dimensions %d X %d\" %(XTrainFlatten.shape))\n",
    "print(\"X Test data dimensions %d X %d\" %(XTestFlatten.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_sample_per_activity = dict([(v,50) for k,v in ACTIVITY_DIC.items()])\n",
    "linestyle_per_activity = dict([(v,\"solid\") for k,v in ACTIVITY_DIC.items()])\n",
    "linewidth_per_activity = dict([(v,1)for k,v in ACTIVITY_DIC.items()])\n",
    "\n",
    "fig = plt.figure(figsize=(18,18))    \n",
    "uil.plot_signaux(fig, XTrainSignals, np.array(ytrain_label), SIGNALS, COLOR_DIC, nb_sample_per_activity, \n",
    "             linestyle_per_activity, linewidth_per_activity, figdim1 = 3, figdim2 = 3, shuffle=True, legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display only one signal\n",
    "We only represent here the first signal (body acceleration in x), for the 6 classes, on $10$ individuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "nb_sample = 10\n",
    "isignal=0    \n",
    "uil.plot_signal_per_activity(fig, XTestSignals, ytest_label, nb_sample, isignal, SIGNALS, COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Choose one of the signal (Walking upstairs for example). What makes the Euclidean metric (L2) ineffective for this signal?\n",
    "\n",
    "**Q** Why it is interesting to decompose the signal in the frequency domain in term of correlation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "####  Principal Components Analysis\n",
    "##### On one signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sdec.PCA()\n",
    "isignal = 4\n",
    "signal = SIGNALS[isignal]\n",
    "print(\"PCA on  signal : \" +signal)\n",
    "X_r = pca.fit_transform(XTrainSignals[:,:,isignal])\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, pca, X_r, whis=100)\n",
    "fig.suptitle(\" PCA results on the Signal : \" + signal, fontsize=25)\n",
    "\n",
    "colors=[COLOR_DIC[y] for y in ytrain_label]\n",
    "markersizes = [20 for _ in range(N_train)]\n",
    "fig = plt.figure(figsize=(10,10), )\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_pca(ax,X_r, pca, 1, 2, colors, markersizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Over all signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sdec.PCA()\n",
    "print(\"PCA on all the signals\")\n",
    "X_r = pca.fit_transform(XTrainFlatten)\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, pca, X_r)\n",
    "fig.suptitle(\"PCA results on all the signals\", fontsize=25)\n",
    "fig = plt.figure(figsize=(10,10), )\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_pca(ax,X_r, pca, 1, 2, colors, markersizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Linear discriminant analysis\n",
    "##### on one signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isignal = 0\n",
    "signal = SIGNALS[isignal]\n",
    "print(\"LDA on  signal : \" +signal)\n",
    "\n",
    "method = sda.LinearDiscriminantAnalysis() \n",
    "lda=method.fit(XTrainSignals[:,:,isignal],ytrain_label)\n",
    "X_r2=lda.transform(XTrainSignals[:,:,isignal])\n",
    "\n",
    "fig = plt.figure(figsize= (20,20))\n",
    "count = 0\n",
    "for nbc, nbc2, count in [(1,2,1), (2,3,2), (3,4,3), (1,3,4), (2,4,5), (1,4,7)] :\n",
    "    ax = fig.add_subplot(3,3,count)\n",
    "    uil.plot_pca(ax,X_r2, lda, nbc, nbc2, colors, markersizes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### over all signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LDA on all the signals\")\n",
    "\n",
    "method = sda.LinearDiscriminantAnalysis() \n",
    "lda=method.fit(XTrainFlatten,ytrain_label)\n",
    "X_r2=lda.transform(XTrainFlatten)\n",
    "\n",
    "fig = plt.figure(figsize= (20,20))\n",
    "count = 0\n",
    "for nbc, nbc2, count in [(1,2,1), (2,3,2), (3,4,3), (1,3,4), (2,4,5), (1,4,7)] :\n",
    "    ax = fig.add_subplot(3,3,count)\n",
    "    uil.plot_pca(ax,X_r2, lda, nbc, nbc2, colors, markersizes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised classification with the logistic regression on the raw signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "method = LogisticRegression()\n",
    "method.fit(XTrainFlatten,ytrain)\n",
    "score = method.score(XTestFlatten, ytest)\n",
    "ypred = method.predict(XTestFlatten)\n",
    "ypred_label = np.array([ACTIVITY_DIC[y] for y in ypred])\n",
    "te = time.time()\n",
    "\n",
    "print(\"Score : %f, time running : %d secondes\" %(score, te-ts))\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sb.heatmap(pd.crosstab(np.array(ytest_label), ypred_label, rownames=['True'], colnames=['Pred']), annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What can you say about these results?\n",
    "\n",
    "**Exercise** If you have time at the end of the TP, try to achieve better results, using different models (SVM, Random Forest, Xgboost) of different combination of the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Wavelet Decomposition of the raw signals\n",
    "\n",
    "Since the supervised classification performed on the raw signal gives bad performances, we try to improve these results by transforming the raw signals with a wavelet decomposition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient Illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_to_plot = 1\n",
    "index_per_act_dict = dict([(act, np.where(ytrain==act)[0][:sample_to_plot]) for act in range(1,7)])\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "for ip, (act , index) in enumerate(index_per_act_dict.items()):\n",
    "    ax=fig.add_subplot(2,3,ip+1)\n",
    "    coef = pywt.wavedec(XTrainFlatten[index,:1024], 'db1')\n",
    "    uil.coef_pyramid_plot(ax, coef[1:]) ;\n",
    "\n",
    "    ax.set_title(ACTIVITY_DIC[act]);\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_db_list = pywt.wavedec(XTrainFlatten, 'db1')\n",
    "N_per_activity_train = collections.Counter(np.array(ytrain))\n",
    "uil.plot_boxplot_coef_concat_per_signal(X_train_db_list, np.array(ytrain), labels=LABELS, activity_dic=ACTIVITY_DIC, \n",
    "                             color_dic=COLOR_DIC, N_per_activity_train= N_per_activity_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Explain what is represented on all theses graphs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Exploration of the wavelet coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA on all the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_db = np.concatenate(pywt.wavedec(XTrainFlatten, 'db1'), axis=1)\n",
    "X_test_db = np.concatenate(pywt.wavedec(XTestFlatten, 'db1'), axis=1)\n",
    "\n",
    "## PCA \n",
    "pca = sdec.PCA()\n",
    "X_train_db_pca = pca.fit_transform(X_train_db)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, pca, X_train_db_pca)\n",
    "\n",
    "fig = plt.figure(figsize= (20,20))\n",
    "count = 0\n",
    "for nbc, nbc2, count in [(1,2,1), (2,3,2), (3,4,3), (1,3,4), (2,4,5), (1,4,7)] :\n",
    "    ax = fig.add_subplot(3,3,count)\n",
    "    uil.plot_pca(ax,X_train_db_pca, pca, nbc, nbc2, colors, markersizes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the thresholded coefficients\n",
    "\n",
    "We use a soft thresholding on the wavelet coefficients in order to remove some noise from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cA10, cD10, cD9, cD8, cD7, cD6, cD5, cD4, cD3, cD2, cD1 = pywt.wavedec(XTrainFlatten, 'db1')\n",
    "\n",
    "sigma=0.01\n",
    "thresh = sigma*np.sqrt(2*np.log((XTrainFlatten.shape[1])))\n",
    "\n",
    "# On seuille seulement les coefficients de détail : \n",
    "cD10=pywt.threshold(cD10, thresh, 'soft')\n",
    "cD9=pywt.threshold(cD9, thresh, 'soft')\n",
    "cD8=pywt.threshold(cD8, thresh, 'soft')\n",
    "cD7=pywt.threshold(cD7, thresh, 'soft')\n",
    "cD6=pywt.threshold(cD6, thresh, 'soft')\n",
    "cD5=pywt.threshold(cD5, thresh, 'soft')\n",
    "cD4=pywt.threshold(cD4, thresh, 'soft')\n",
    "cD3=pywt.threshold(cD3, thresh, 'soft')\n",
    "cD2=pywt.threshold(cD2, thresh, 'soft')\n",
    "cD1=pywt.threshold(cD1, thresh, 'soft')\n",
    "\n",
    "X_train_dbth = np.concatenate((cA10, cD10, cD9, cD8, cD7, cD6, cD5, cD4, cD3, cD2, cD1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cA10, cD10, cD9, cD8, cD7, cD6, cD5, cD4, cD3, cD2, cD1 = pywt.wavedec(XTestFlatten, 'db1')\n",
    "\n",
    "sigma=0.01\n",
    "thresh = sigma*np.sqrt(2*np.log((XTestFlatten.shape[1])))\n",
    "\n",
    "# On seuille seulement les coefficients de détail : \n",
    "cD10=pywt.threshold(cD10, thresh, 'soft')\n",
    "cD9=pywt.threshold(cD9, thresh, 'soft')\n",
    "cD8=pywt.threshold(cD8, thresh, 'soft')\n",
    "cD7=pywt.threshold(cD7, thresh, 'soft')\n",
    "cD6=pywt.threshold(cD6, thresh, 'soft')\n",
    "cD5=pywt.threshold(cD5, thresh, 'soft')\n",
    "cD4=pywt.threshold(cD4, thresh, 'soft')\n",
    "cD3=pywt.threshold(cD3, thresh, 'soft')\n",
    "cD2=pywt.threshold(cD2, thresh, 'soft')\n",
    "cD1=pywt.threshold(cD1, thresh, 'soft')\n",
    "\n",
    "X_test_dbth = np.concatenate((cA10, cD10, cD9, cD8, cD7, cD6, cD5, cD4, cD3, cD2, cD1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA\n",
    "pca = sdec.PCA()\n",
    "X_train_dbth_pca = pca.fit_transform(X_train_dbth)\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, pca, X_train_db_pca)\n",
    "fig = plt.figure(figsize= (20,20))\n",
    "count = 0\n",
    "for nbc, nbc2, count in [(1,2,1), (2,3,2), (3,4,3), (1,3,4), (2,4,5), (1,4,7)] :\n",
    "    ax = fig.add_subplot(3,3,count)\n",
    "    uil.plot_pca(ax,X_train_dbth_pca, pca, nbc, nbc2, colors, markersizes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Comment the results. Does the thresholding seem to have an influence ? You can change the value of sigma. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised classification with the logistic regression on the wavelet coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "method = LogisticRegression()\n",
    "method.fit(X_train_dbth,ytrain)\n",
    "score = method.score(X_test_dbth, ytest)\n",
    "ypred = method.predict(X_test_dbth)\n",
    "ypred_label = np.array([ACTIVITY_DIC[y] for y in ypred])\n",
    "te = time.time()\n",
    "\n",
    "print(\"Score : %f, time running : %d secondes\" %(score, te-ts))\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sb.heatmap(pd.crosstab(np.array(ytest_label), ypred_label, rownames=['True'], colnames=['Pred']), annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Compare with the results obtained on the raw data and on the features data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Fourier Transform\n",
    "\n",
    "Since the wavelet decomposition did not allow to obtain good classification results, we now consider Fourier coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients fft : \n",
    "\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "\n",
    "isignal = 0\n",
    "\n",
    "XTrain_fftCoeff = []\n",
    "\n",
    "for x in XTrainFlatten :\n",
    "    \n",
    "    mx=np.mean(x)\n",
    "    x_centre=x-mx\n",
    "   #Apply fast Fourier transform\n",
    "    coeffsfft=np.abs(fft(x_centre))  \n",
    "    coeffsfft_flatten = np.hstack(coeffsfft)\n",
    "    XTrain_fftCoeff.append(coeffsfft_flatten)\n",
    "        \n",
    "XTrain_fftCoeff = np.array(XTrain_fftCoeff)\n",
    "\n",
    "# Il suffit de garder la moitié des coefficients (ils sont ensuite répétés  de manière symétrique)\n",
    "\n",
    "XTrain_fftCoeff=XTrain_fftCoeff[:,:64]\n",
    "print(XTrain_fftCoeff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isignal = 0\n",
    "\n",
    "XTest_fftCoeff = []\n",
    "\n",
    "for x in XTestFlatten :\n",
    "    \n",
    "    mx=np.mean(x)\n",
    "    x_centre=x-mx\n",
    "   #Apply fast Fourier transform\n",
    "    coeffsfft=np.abs(fft(x_centre))  \n",
    "    coeffsfft_flatten = np.hstack(coeffsfft)\n",
    "    XTest_fftCoeff.append(coeffsfft_flatten)\n",
    "        \n",
    "XTest_fftCoeff = np.array(XTest_fftCoeff)\n",
    "\n",
    "\n",
    "XTest_fftCoeff=XTest_fftCoeff[:,:64]\n",
    "print(XTest_fftCoeff.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA for FFT  coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## PCA \n",
    "pca = sdec.PCA()\n",
    "X_train_fftCoeff_pca = pca.fit_transform(XTrain_fftCoeff)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, pca, X_train_fftCoeff_pca)\n",
    "\n",
    "fig = plt.figure(figsize= (20,20))\n",
    "count = 0\n",
    "for nbc, nbc2, count in [(1,2,1), (2,3,2), (3,4,3), (1,3,4), (2,4,5), (1,4,7)] :\n",
    "    ax = fig.add_subplot(3,3,count)\n",
    "    uil.plot_pca(ax,X_train_fftCoeff_pca, pca, nbc, nbc2, colors, markersizes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Comment the results. Which classes are well separated on the first plane of the PCA ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised classification with the logistic regression on the FFT coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "method = LogisticRegression()\n",
    "method.fit(XTrain_fftCoeff,ytrain)\n",
    "score = method.score(XTest_fftCoeff, ytest)\n",
    "ypred = method.predict(XTest_fftCoeff)\n",
    "ypred_label = np.array([ACTIVITY_DIC[y] for y in ypred])\n",
    "te = time.time()\n",
    "\n",
    "print(\"Score : %f, time running : %d secondes\" %(score, te-ts))\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sb.heatmap(pd.crosstab(np.array(ytest_label), ypred_label, rownames=['True'], colnames=['Pred']), annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Compare these results with the ones obtained with wavelet coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer perceptrons and  Convolutional Neural Networks\n",
    "\n",
    "We try here to improve the classification results by applying multilayer perceptrons and  convolutional neural networks on the raw signals. \n",
    "\n",
    "As explained in the introduction, calculating many transformations of the data such as the features used in the first part is too resource-consuming for the battery of a connected smartphone. This section proposes to use only the raw signals to train a neural network that could be \"wired\" in the circuit. Indeed an algorithm such as XGBoost (extreme gradient boosting) also achieves good results on raw signals but at a too high algorithmic cost.\n",
    "\n",
    "Three algorithms are successively tested: a multilayer perceptron, followed by a 1D convolutional neural network on the flatten signals, and finally a 2D convolutional neural network on the 9 signals.\n",
    "\n",
    "It should be added that many configurations have been tested, thanks  to the students of INSA Toulouse of the  Applied Mathematics - Data Science speciality, before adopting the ones proposed here. It is a reality of deep learning, without  precise theoretical results, only an experimental  approach  allows to determine a more efficient configuration. Other network architectures would have to be tested to reach the 96% of the previous solution.\n",
    "\n",
    "**Q.** In each case, describe the model that is used, explain the number of parameters of the model and comment the performances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEEP LEARNING libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.models as km \n",
    "import tensorflow.keras.layers as kl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP on unidimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "n_features = XTrainFlatten.shape[1]\n",
    "n_classes=6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Build a multilayer perceptron named \"model_base_mlp_u\", with the following layers : \n",
    "\n",
    "  * a dense layer with 32 neurons and activation function relu\n",
    "  * a dropout layer with a dropout probability equal to 0.5 \n",
    "  * the output layer is a dense layer with 6 neurons and the softmax activation function \n",
    "  \n",
    "  Print the summary of the model. Retrieve the number of parameters and the output shape of each layer of the model. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/dense1D.py\n",
    "# MLP on unidimensional data\n",
    "n_hidden = 32\n",
    "model_base_mlp_u =km.Sequential()\n",
    "model_base_mlp_u.add(kl.Dense(n_hidden, input_shape=(n_features,),  activation = \"relu\"))\n",
    "model_base_mlp_u.add(kl.Dropout(0.5))\n",
    "model_base_mlp_u.add(kl.Dense(n_classes, activation='softmax'))\n",
    "model_base_mlp_u.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_base_mlp_u.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "model_base_mlp_u.fit(XTrainFlatten,  ytrain-1, batch_size=batch_size, validation_data=(XTestFlatten, ytest-1), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_mlp_u.evaluate(XTestFlatten,ytest-1)[1] \n",
    "print(\"Score With Simple MLP on Inertial Signals = %.2f, Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_mlp_u = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_mlp_u_prediction = model_base_mlp_u.predict(XTestFlatten)\n",
    "y_pred_label = [ACTIVITY_DIC[x] for x in base_mlp_u_prediction.argmax(axis=1)+1]\n",
    "\n",
    "print(\"Score : %f, time running : %d secondes\" %(score, te-ts))\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sb.heatmap(pd.crosstab(np.array(ytest_label), ypred_label, rownames=['True'], colnames=['Pred']), annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### On multi-dimensional signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 50\n",
    "timesteps = len(XTrainSignals[0])\n",
    "input_dim = len(XTrainSignals[0][0])\n",
    "n_classes = 6\n",
    "\n",
    "model_base_mlp =km.Sequential()\n",
    "model_base_mlp.add(kl.Dense(n_hidden, input_shape=(timesteps, input_dim),  activation = \"relu\"))\n",
    "model_base_mlp.add(kl.Reshape((timesteps*n_hidden,) , input_shape= (timesteps, n_hidden)  ))\n",
    "model_base_mlp.add(kl.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_base_mlp.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_base_mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Retrieve the number of parameters and the output shape of each layer of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "model_base_mlp.fit(XTrainSignals,  ytrain-1, batch_size=batch_size, validation_data=(XTestSignals, ytest-1), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_mlp.evaluate(XTestSignals, ytest-1)[1] \n",
    "print(\"Score With Simple MLP on Multidimensional Inertial Signals = %.2f, Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_mlp = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_mlp_prediction = model_base_mlp.predict(XTestSignals)\n",
    "\n",
    "y_pred_label = [ACTIVITY_DIC[x] for x in base_mlp_prediction.argmax(axis=1)+1]\n",
    "\n",
    "print(\"Score : %f, time running : %d secondes\" %(score, te-ts))\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sb.heatmap(pd.crosstab(np.array(ytest_label), ypred_label, rownames=['True'], colnames=['Pred']), annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_conv_1D =km.Sequential()\n",
    "model_base_conv_1D.add(kl.Conv1D(32, 5, activation='relu', input_shape=(timesteps, input_dim)))\n",
    "model_base_conv_1D.add(kl.MaxPooling1D(pool_size=3))\n",
    "model_base_conv_1D.add(kl.Flatten())\n",
    "model_base_conv_1D.add(kl.Dense(n_classes, activation='softmax'))\n",
    "model_base_conv_1D.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_base_conv_1D.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Retrieve the number of parameters and the output shape of each layer of the model and understand how the 1D convolution acts on the signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "model_base_conv_1D.fit(XTrainSignals,  ytrain-1, batch_size=batch_size, validation_data=(XTestSignals, ytest-1), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_conv_1D.evaluate(XTestSignals, ytest-1)[1] \n",
    "print(\"Score With Conv on Multidimensional Inertial Signals = %.2f, Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_conv = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_conv_1D_prediction = model_base_conv_1D.predict(XTestSignals)\n",
    "\n",
    "y_pred_label = [ACTIVITY_DIC[x] for x in base_conv_1D_prediction.argmax(axis=1)+1]\n",
    "\n",
    "print(\"Score : %f, time running : %d secondes\" %(score, te-ts))\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sb.heatmap(pd.crosstab(np.array(ytest_label), ypred_label, rownames=['True'], colnames=['Pred']), annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Comment the results. \n",
    "\n",
    "**Q.** Modify the parameters of the Conv1D layer. Do you improve the performances ? \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2D Convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_conv_2D =km.Sequential()\n",
    "model_base_conv_2D.add(kl.Conv2D(32, (3, 3),strides=(3,3), activation='relu', input_shape=(timesteps, input_dim, 1)))\n",
    "model_base_conv_2D.add(kl.MaxPooling2D(pool_size=(2, 1)))\n",
    "model_base_conv_2D.add(kl.Flatten())\n",
    "model_base_conv_2D.add(kl.Dense(n_classes, activation='softmax'))\n",
    "model_base_conv_2D.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model_base_conv_2D.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Retrieve the number of parameters and the output shape of each layer of the model and understand how the 2D convolution acts on the signals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_conv = np.expand_dims(XTrainSignals, -1)\n",
    "X_test_conv = np.expand_dims(XTestSignals, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "model_base_conv_2D.fit(X_train_conv,  ytrain-1, batch_size=batch_size, validation_data=(X_test_conv, ytest-1), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_conv_2D.evaluate(X_test_conv, ytest-1)[1] \n",
    "print(\"Score With Conv on Multidimensional Inertial Signals = %.2f, Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_conv = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_conv_2D_prediction = model_base_conv_2D.predict(X_test_conv)\n",
    "\n",
    "y_pred_label = [ACTIVITY_DIC[x] for x in base_conv_1D_prediction.argmax(axis=1)+1]\n",
    "\n",
    "print(\"Score : %f, time running : %d secondes\" %(score, te-ts))\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sb.heatmap(pd.crosstab(np.array(ytest_label), ypred_label, rownames=['True'], colnames=['Pred']), annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Comment the results. \n",
    "\n",
    "**Q.** Modify the size of the kernels in the first layer and the Maxpooling layer to recover the same results as the previous  1D convolutional network.\n",
    "  \n",
    "**Q.** Compare all the results and conclude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
