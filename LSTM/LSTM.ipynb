{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting Using RNN Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Packages Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T06:05:28.477844Z",
     "start_time": "2020-04-28T06:05:19.938799Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import h5py  # Output network weights in HDF5 format during checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Input, Dense, Embedding, Flatten, AveragePooling1D\n",
    "from keras.layers import SimpleRNN, LSTM, Bidirectional, TimeDistributed, ConvLSTM2D\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Dataset and Objective\n",
    "\n",
    "The ultimate goal of the lab is to study the `covid19` dataset that compiles the number of confirmed cases and fatalities for different countries and province states around the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:56:22.640117Z",
     "start_time": "2020-04-27T06:56:22.571515Z"
    }
   },
   "outputs": [],
   "source": [
    "covid19 = pd.read_csv('covid19.csv', parse_dates=[3], infer_datetime_format=True)\n",
    "\n",
    "print(\"covid19.shape\", covid19.shape)\n",
    "display(covid19.dtypes)\n",
    "covid19.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, the following states can be observed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covid19[\"Province_State\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate the visualization of the dataset, we add a column to count the number of days since our first observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:56:23.447306Z",
     "start_time": "2020-04-27T06:56:23.432601Z"
    }
   },
   "outputs": [],
   "source": [
    "print(covid19['Date'].min())\n",
    "covid19['Days'] = covid19['Date']-covid19['Date'].min()\n",
    "covid19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T17:30:04.902370Z",
     "start_time": "2020-04-27T17:30:04.831793Z"
    }
   },
   "outputs": [],
   "source": [
    "STATE = \"New York\"\n",
    "\n",
    "df = covid19[covid19[\"Province_State\"]==STATE]\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "mpl.style.use(\"bmh\")\n",
    "plt.plot(df[\"Date\"], df['ConfirmedCases'], label='Confirmed')\n",
    "plt.plot(df[\"Date\"], df['Fatalities'], label='Fatalities')\n",
    "plt.legend()\n",
    "plt.title(\"Cases in \"+STATE)\n",
    "plt.ylabel(\"Cases number\")\n",
    "plt.xlabel(\"Days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidelines\n",
    "\n",
    "We wish to solve the supervised learning problem corresponding to the prediction of confirmed cases for the next 10 days based on the known cases of the previous 30 days.  Once this is done, we would like to jointly predict the confirmed cases and the fatalities.\n",
    "\n",
    "To do this, first make sure you understand the different variants of the LSTM algorithm presented below, except for the parts marked with a purple \"To Go Further\". If necessary, complete the relevant codes. \n",
    "Then, answer the problem posed using the codes provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:56:25.492435Z",
     "start_time": "2020-04-27T06:56:25.488356Z"
    }
   },
   "outputs": [],
   "source": [
    "confirmed = np.array(df['ConfirmedCases']).reshape(-1, 1)\n",
    "fatalities = np.array(df['Fatalities']).reshape(-1, 1)\n",
    "\n",
    "print(\"Confirmed cases in \"+STATE+\":\",confirmed.shape,\";  Fatalities in \"+STATE+\":\", fatalities.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_fit(inputs, predictions, X_train, y_train, X_test, y_test):\n",
    "    # This creates a model that includes\n",
    "    # the Input layer and three Dense layers\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "    # print the network\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)  # early stopping to prevent overfitting\n",
    "    mc = ModelCheckpoint(\"model.hdf5\", monitor=\"val_mae\", mode=\"min\", save_best_only=True)\n",
    "    callbacks = [es, mc]\n",
    "\n",
    "    history = model.fit(X_train[:-SPLIT], y_train[:-SPLIT], epochs=200,\n",
    "                        validation_data=[X_train[-SPLIT:], y_train[-SPLIT:]],\n",
    "                        callbacks=callbacks, verbose=0, shuffle=False)\n",
    "    model = load_model(\"model.hdf5\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # plot history\n",
    "    plt.figure(figsize=(16,4))\n",
    "    mpl.style.use(\"seaborn-colorblind\")\n",
    "    ax = plt.gca()\n",
    "\n",
    "    if len(y_train.shape)==2:  # Univariate data\n",
    "        plt.subplot(131)\n",
    "        plt.plot(history.history['loss'][3:], label='loss')\n",
    "        plt.plot(history.history['val_loss'][3:], label='val_loss')\n",
    "        plt.legend(loc='center right')\n",
    "    \n",
    "        plt.subplot(132)\n",
    "        plt.plot(history.history['mae'][3:], label='mae')\n",
    "        plt.plot(history.history['val_mae'][3:], label='val_mae')\n",
    "        plt.legend(loc='center right')\n",
    "    \n",
    "        plt.subplot(133)\n",
    "        color = next(ax._get_lines.prop_cycler)['color']\n",
    "        plt.plot(range(len(y_train)), y_train, label=\"train\",color=color)\n",
    "        color = next(ax._get_lines.prop_cycler)['color']\n",
    "        plt.plot(range(len(y_train), len(y_train)+len(y_test)), y_test, label=\"test\",color=color)\n",
    "        color = next(ax._get_lines.prop_cycler)['color']\n",
    "        plt.plot(range(len(y_train), len(y_train)+len(y_pred)), y_pred, label=\"predict\",color=color)\n",
    "        plt.legend(loc='upper left')\n",
    "    else:\n",
    "        subplot=str(y_pred.shape[1]+2)+str(y_pred.shape[1]+2)\n",
    "        \n",
    "        plt.subplot(int(subplot+\"1\"))\n",
    "        plt.plot(history.history['loss'][3:], label='loss')\n",
    "        plt.plot(history.history['val_loss'][3:], label='val_loss')\n",
    "        plt.legend(loc='center right')\n",
    "    \n",
    "        plt.subplot(int(subplot+\"2\"))\n",
    "        plt.plot(history.history['mae'][3:], label='mae')\n",
    "        plt.plot(history.history['val_mae'][3:], label='val_mae')\n",
    "        plt.legend(loc='center right')\n",
    "    \n",
    "        for i in range(y_pred.shape[1]):\n",
    "            plt.subplot(int(subplot+str(i+3)))\n",
    "            color = next(ax._get_lines.prop_cycler)['color']\n",
    "            plt.plot(range(len(y_train)), y_train[:,i,:], label=\"train\"+str(i),color=color)\n",
    "            color = next(ax._get_lines.prop_cycler)['color']\n",
    "            plt.plot(range(len(y_train), len(y_train)+len(y_test)), y_test[:,i,:], label=\"test\"+str(i),color=color)\n",
    "            color = next(ax._get_lines.prop_cycler)['color']\n",
    "            plt.plot(range(len(y_train), len(y_train)+len(y_pred)), y_pred[:,i,:], label=\"predict\"+str(i),color=color)\n",
    "            plt.legend(loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## LSTM Network for Univariate Time Series\n",
    "\n",
    "LSTM can be used to model univariate time series forecasting problems. These problems consist of a single set of observations and a model is needed to learn from the past set of observations in order to forecast the next value in the sequence. Before considering our multivariate dataset, we will test different variants of the RNN algrithm, and more precisely the LSTM, on univariate synthetic data.\n",
    "\n",
    "Be careful not to draw hasty conclusions about the relative performance of the models. The number of layers or neurons are highly variable between models.\n",
    "\n",
    "<!-- _To do:_ time series where you want to predict, a sequence instead of a single value. -->\n",
    "\n",
    "\n",
    "### Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:56:26.334395Z",
     "start_time": "2020-04-27T06:56:26.330717Z"
    }
   },
   "outputs": [],
   "source": [
    "SIZE = 100\n",
    "n_features = 1 # for univariate time series\n",
    "\n",
    "fct = lambda x: x*np.sin(x)\n",
    "time_series = [fct(x) for x in range(SIZE)]\n",
    "\n",
    "plt.plot(time_series)\n",
    "mpl.style.use(\"bmh\")\n",
    "plt.title(\"Synthetic Dataset for Univariate Study\")\n",
    "plt.ylabel(\"$x\\,\\sin(x)$\")\n",
    "plt.xlabel(\"$x$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a given univariate sequence:\n",
    "\n",
    "`[10, 20, 30, 40, 50, 60, 70, 80, 90]`\n",
    "\n",
    "We can divide the sequence into multiple input/output patterns called samples, where three time steps are used as input and one time step is used as output for the one-step prediction that is being learned.\n",
    "\n",
    "`X \t\t\t\ty ` <br/>\n",
    "`10, 20, 30\t\t40` <br/>\n",
    "`20, 30, 40\t\t50` <br/>\n",
    "`30, 40, 50\t\t60` <br/>\n",
    "`...` <br/>\n",
    "\n",
    "The $\\texttt{convert_data_univariate()}$ function below implements this behavior and will split a given univariate sequence into multiple samples where each sample has a specified number of time steps `n_in` (by default 3) and the output has also a specified number of time steps `n_out` (by default 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:56:27.528368Z",
     "start_time": "2020-04-27T06:56:27.523079Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_data_univariate(data, n_in=3, n_out=1):\n",
    "    X, y = [], []\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(len(data)):\n",
    "        # find the end of this pattern\n",
    "        end_x = i + n_in\n",
    "        end_y = end_x + n_out\n",
    "        # check if we are beyond the sequence\n",
    "        if end_y > len(data):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = data[i:end_x], data[end_x:end_y]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into samples\n",
    "n_in, n_out = 6, 1\n",
    "X, y = convert_data_univariate(time_series, n_in, n_out)\n",
    "\n",
    "# Summarize the data\n",
    "for i in range(3):\n",
    "    print(\"-\"*15)\n",
    "    print(\"X:\", X[i])\n",
    "    print(\"y:\", y[i])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:56:28.817232Z",
     "start_time": "2020-04-27T06:56:28.814585Z"
    }
   },
   "outputs": [],
   "source": [
    "testAndValid = 0.1\n",
    "SPLIT = int(testAndValid*len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The form of the input for each sample is specified in the `input_shape` argument on the definition of the first hidden layer. The model expects the input component for training data to have the dimensions or shape `[samples, timesteps, features]` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape from [samples, timesteps] into [samples, n_in, n_features]\n",
    "X_train = X.reshape((X.shape[0], X.shape[1], n_features))[:-SPLIT]\n",
    "X_test = X.reshape((X.shape[0], X.shape[1], n_features))[-SPLIT:]\n",
    "\n",
    "y_train, y_test = y[:-SPLIT], y[-SPLIT:]\n",
    "\n",
    "print(\"X_train:\",X_train.shape,\"; X_test:\", X_test.shape)\n",
    "print(\"y_train:\",y_train.shape,\"   ; y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN\n",
    "\n",
    "##### <span style=\"color:purple\">**Todo:** Determine the size of the input vectors in the network.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_SIZE = 30\n",
    "\n",
    "inputs = Input(shape=(...))  # To be completed\n",
    "outputs = SimpleRNN(RNN_SIZE, return_sequences=False, activation='tanh')(inputs)\n",
    "predictions = Dense(n_out, activation='linear')(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Build the model.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_and_fit(...)  # To be completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Evaluate the prediction.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the prediction (To be completed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:56:31.261133Z",
     "start_time": "2020-04-27T06:56:31.143595Z"
    }
   },
   "outputs": [],
   "source": [
    "LSTM_SIZE = 30\n",
    "\n",
    "inputs = Input(shape=(n_in, n_features))  # To be completed\n",
    "outputs = LSTM(LSTM_SIZE, return_sequences=False, recurrent_activation='sigmoid', activation='relu')(inputs)\n",
    "predictions = Dense(n_out, activation='linear')(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_and_fit(inputs, predictions, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Evaluate the prediction.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:56:38.772372Z",
     "start_time": "2020-04-27T06:56:38.767207Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the prediction (To be completed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Bi-LSTM\n",
    "\n",
    "In order to improve the performance of the model, it's possible to:\n",
    "- stack LSTM with `return_sequence=True` for all levels except the last one where `return_sequence=False`\n",
    "- use Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:56:39.336890Z",
     "start_time": "2020-04-27T06:56:38.773903Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(n_in, n_features))\n",
    "outputs = Bidirectional(LSTM(LSTM_SIZE, return_sequences=True, activation='relu'))(inputs)\n",
    "outputs = Bidirectional(LSTM(LSTM_SIZE, return_sequences=True, activation='relu'))(outputs)\n",
    "outputs = Bidirectional(LSTM(LSTM_SIZE, return_sequences=False, activation='relu'))(outputs)\n",
    "predictions = Dense(n_out, activation='linear')(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:56:51.293762Z",
     "start_time": "2020-04-27T06:56:39.339180Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_and_fit(inputs, predictions, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Evaluate the prediction.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:56:51.302271Z",
     "start_time": "2020-04-27T06:56:51.295394Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the prediction (To be completed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Kind of Networks <span style=\"color:purple\">(To Go Further)</span>\n",
    "\n",
    "#### CNN-LSTM\n",
    "\n",
    "A CNN model can be used in a hybrid model with an LSTM backend where the CNN is used to interpret subsequences of input that together are provided as a sequence to an LSTM model to interpret.\n",
    "\n",
    "The first step is to split the input sequences into subsequences that can be processed by the CNN model. For example, we can first split our univariate time series data into input/output samples with four steps as input and one as output. Each sample can then be split into two sub-samples, each with two time steps. The CNN can interpret each subsequence of two time steps and provide a time series of interpretations of the subsequences to the LSTM model to process as input.\n",
    "\n",
    "We can parameterize this and define the number of subsequences as `n_seq` and the number of time steps per subsequence as `n_steps`. The input data can then be reshaped to have the required structure: `[samples, subsequences, timesteps, features]`.\n",
    "\n",
    "`n_step` is the number of time steps per subsequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:56:51.307379Z",
     "start_time": "2020-04-27T06:56:51.303326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape from [samples, timesteps] into [samples, subsequences, n_steps, n_features]\n",
    "n_seq = 2 # subsequence size\n",
    "if n_in % n_seq == 0:\n",
    "    n_steps = n_in // n_seq\n",
    "else:\n",
    "    print(\"bad subsequence value\")\n",
    "    stop()\n",
    "X_train = X.reshape((X.shape[0], n_seq, n_steps, n_features))[:-SPLIT]\n",
    "X_test = X.reshape((X.shape[0], n_seq, n_steps, n_features))[-SPLIT:]\n",
    "\n",
    "y_train = y[:-SPLIT]\n",
    "y_test = y[-SPLIT:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:56:51.478731Z",
     "start_time": "2020-04-27T06:56:51.309789Z"
    }
   },
   "outputs": [],
   "source": [
    "CNN_SIZE = 16\n",
    "\n",
    "inputs = Input(shape=(n_seq,n_steps,n_features))\n",
    "outputs = TimeDistributed(Conv1D(filters=CNN_SIZE, kernel_size=1, activation='relu'))(inputs)\n",
    "outputs = TimeDistributed(MaxPooling1D(pool_size=2))(outputs)\n",
    "outputs = TimeDistributed(Flatten())(outputs)\n",
    "outputs = TimeDistributed(Flatten())(outputs)\n",
    "outputs = LSTM(50, activation='relu')(outputs)\n",
    "predictions = Dense(n_out, activation='linear')(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:57:01.306462Z",
     "start_time": "2020-04-27T06:56:51.480631Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_and_fit(inputs, predictions, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:57:01.316704Z",
     "start_time": "2020-04-27T06:57:01.308775Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate prediction\n",
    "start = 12\n",
    "y_true = fct(start+n_in)\n",
    "x_input = np.array([fct(x) for x in range(start,start+n_in)])\n",
    "x_input = x_input.reshape((1, n_seq, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ConvLSTM\n",
    "\n",
    "A type of LSTM related to the CNN-LSTM is the ConvLSTM, where the convolutional reading of input is built directly into each LSTM unit.\n",
    "\n",
    "The ConvLSTM was developed for reading two-dimensional spatial-temporal data, but can be adapted for use with univariate time series forecasting.\n",
    "\n",
    "The layer expects input as a sequence of two-dimensional images, therefore the shape of input data must be: `[samples, timesteps, rows, columns, features]`.\n",
    "\n",
    "For our purposes, we can split each sample into subsequences where timesteps will become the number of subsequences, or n_seq, and columns will be the number of time steps for each subsequence, or n_steps. The number of rows is fixed at 1 as we are working with one-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:57:01.323821Z",
     "start_time": "2020-04-27T06:57:01.318558Z"
    }
   },
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, subsequences, n_steps, n_features]\n",
    "n_seq = 2 # subsequence size\n",
    "if n_in % n_seq == 0:\n",
    "    n_steps = n_in // n_seq\n",
    "else:\n",
    "    print(\"bad subsequence value\")\n",
    "    stop()\n",
    "X_train = X.reshape((X.shape[0], n_seq, 1, n_steps, n_features))[:-SPLIT]\n",
    "X_test = X.reshape((X.shape[0], n_seq, 1, n_steps, n_features))[-SPLIT:]\n",
    "\n",
    "y_train = y[:-SPLIT]\n",
    "y_test = y[-SPLIT:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:57:01.478962Z",
     "start_time": "2020-04-27T06:57:01.325461Z"
    }
   },
   "outputs": [],
   "source": [
    "CNN_SIZE = 16\n",
    "\n",
    "inputs = Input(shape=(n_seq, 1, n_steps, n_features))\n",
    "outputs = ConvLSTM2D(filters=CNN_SIZE, kernel_size=(1,n_steps), activation='relu')(inputs)\n",
    "outputs = Flatten()(outputs)\n",
    "predictions = Dense(n_out, activation='linear')(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:57:13.815607Z",
     "start_time": "2020-04-27T06:57:01.480081Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_and_fit(inputs, predictions, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:57:13.823736Z",
     "start_time": "2020-04-27T06:57:13.817607Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate prediction\n",
    "start = 12\n",
    "y_true = fct(start+n_in)\n",
    "x_input = np.array([fct(x) for x in range(start,start+n_in)])\n",
    "x_input = x_input.reshape((1, n_seq, 1, n_steps, n_out))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## LSTM Network for Multivariate Time Series "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T07:43:30.193873Z",
     "start_time": "2020-04-16T07:43:30.188973Z"
    }
   },
   "source": [
    "Multivariate time series data means data where there is more than one observation for each time step.\n",
    "\n",
    "There are two main models that we may require with multivariate time series data; they are:\n",
    "\n",
    "* Multiple Input Series.\n",
    "* Multiple Parallel Series.\n",
    "\n",
    "Let’s take a look at each in turn.\n",
    "\n",
    "### Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fct2 = lambda x: 2*x\n",
    "\n",
    "time_series1 = np.array([fct(x) for x in range(SIZE)])\n",
    "time_series2 = np.array([fct2(x) for x in range(SIZE)])\n",
    "out_seq = np.array([time_series1[i]+time_series2[i] for i in range(SIZE)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reshape these three arrays of data as a single dataset where each row is a time step, and each column is a separate time series. This is a standard way of storing parallel time series in a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to [rows, columns] structure\n",
    "time_series1 = time_series1.reshape((len(time_series1), 1))\n",
    "time_series2 = time_series2.reshape((len(time_series2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "\n",
    "# Horizontally stack columns\n",
    "dataset = np.hstack((time_series1, time_series2, out_seq))\n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Input Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the univariate time series, we must structure these data into samples with input and output elements.\n",
    "\n",
    "An LSTM model needs sufficient context to learn a mapping from an input sequence to an output value. LSTMs can support parallel input time series as separate variables or features. Therefore, we need to split the data into samples maintaining the order of observations across the two input sequences.\n",
    "\n",
    "If we chose three input time steps, then the first sample would look as follows:\n",
    "\n",
    "Input: `0,      0`</br>\n",
    "`     0.841,  2`</br>\n",
    "`     1.819,  4`\n",
    "\n",
    "Output: `5.819`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:58:57.600498Z",
     "start_time": "2020-04-27T06:58:57.595054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split a multivariate sequence into samples\n",
    "def convert_data_multipleinputseries(data, n_in=3, n_out=1):\n",
    "    X, y = [], []\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(len(data)):\n",
    "        # find the end of this pattern\n",
    "        end_x = i + n_in\n",
    "        end_y = end_x + n_out\n",
    "        # check if we are beyond the sequence\n",
    "        if end_y > len(data):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = data[i:end_x, :-1], data[end_x:end_y, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:58:58.149720Z",
     "start_time": "2020-04-27T06:58:58.143183Z"
    }
   },
   "outputs": [],
   "source": [
    "n_in, n_out = 6, 1\n",
    "\n",
    "X, y = convert_data_multipleinputseries(dataset, n_in, n_out)\n",
    "# Summarize the data\n",
    "for i in range(3):\n",
    "    print(\"-\"*15)\n",
    "    print(\"X:\", X[i])\n",
    "    print(\"y:\", y[i])\n",
    "print(\"...\")\n",
    "\n",
    "# summarize the data\n",
    "#for i in range(3):\n",
    "#    print(X[i], y[i])\n",
    "#print(\"...\")\n",
    "\n",
    "n_features = X.shape[-1] # in order to capture the multi-variate dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any of the varieties of LSTMs in the previous section can be used, such as a Vanilla, Stacked, Bidirectional, CNN, or ConvLSTM model. \n",
    "We will use a Vanilla LSTM where the number of time steps and parallel series (features) are specified for the input layer via the `input_shape` argument.\n",
    "\n",
    "##### <span style=\"color:purple\">**Todo:** Determine the size of the input vectors in the network.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(...)) # To be completed\n",
    "outputs = LSTM(LSTM_SIZE, return_sequences=False, activation='relu')(inputs)\n",
    "predictions = Dense(n_out, activation='linear')(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:58:59.608154Z",
     "start_time": "2020-04-27T06:58:59.342828Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test = X[:-SPLIT], X[-SPLIT:]\n",
    "y_train, y_test = y[:-SPLIT], y[-SPLIT:]\n",
    "\n",
    "print(\"X_train:\",X_train.shape,\"; X_test:\", X_test.shape)\n",
    "print(\"y_train:\",y_train.shape,\"   ; y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:59:13.152862Z",
     "start_time": "2020-04-27T06:59:00.902495Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_and_fit(inputs, predictions, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Evaluate the prediction.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the prediction (To be completed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Parallel Series\n",
    "\n",
    "An alternate time series problem is the case where there are multiple parallel time series and a value must be predicted for each. \n",
    "For example, given the data from the previous section:\n",
    "\n",
    "`[ 0,      0,  0]`</br>\n",
    "`[ 0.841,  2,  2.841]`</br>\n",
    "`[ 1.819,  4,  8.819]`</br>\n",
    "`[ 0.423,  6,  6.423]`\n",
    "\n",
    "We may want to predict the value for each of the three time series for the next time step.This might be referred to as multivariate forecasting. Again, the data must be split into input/output samples in order to train a model. The first sample of this dataset would be:\n",
    "\n",
    "Input:`0,      0,  0`</br>\n",
    "`    0.841,  2,  2.841`</br>\n",
    "`    1.819,  4,  8.819`\n",
    "\n",
    "Output: `0.423,  6,  6.423`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:59:13.158917Z",
     "start_time": "2020-04-27T06:59:13.154862Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split a multivariate sequence into samples\n",
    "def convert_data_multiplesparallelseries(data, n_in=3, n_out=1):\n",
    "    X, y = [], []\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(len(data)):\n",
    "        # find the end of this pattern\n",
    "        end_x = i + n_in\n",
    "        end_y = end_x + n_out\n",
    "        # check if we are beyond the sequence\n",
    "        if end_y > len(data):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = data[i:end_x, :], data[end_x:end_y, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:59:17.450280Z",
     "start_time": "2020-04-27T06:59:17.440766Z"
    }
   },
   "outputs": [],
   "source": [
    "n_in, n_out = 6, 1\n",
    "\n",
    "X, y = convert_data_multiplesparallelseries(dataset, n_in, n_out)\n",
    "if n_out==1:\n",
    "    y = y.reshape(y.shape[0], y.shape[-1])\n",
    "# Summarize the data\n",
    "for i in range(3):\n",
    "    print(\"-\"*15)\n",
    "    print(\"X:\", X[i])\n",
    "    print(\"y:\", y[i])\n",
    "print(\"...\")\n",
    "\n",
    "n_features = X.shape[-1] # in order to capture the multi-variate dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any of the varieties of LSTMs in the previous section can be used, such as a Vanilla, Stacked, Bidirectional, CNN, or ConvLSTM model. We will use a Stacked Bi-LSTM where the number of time steps and parallel series (features) are specified for the input layer via the `input_shape` argument. The number of parallel series is also used in the specification of the number of values to predict by the model in the output layer; again, this is three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:59:19.220818Z",
     "start_time": "2020-04-27T06:59:18.688076Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(n_in, n_features))\n",
    "outputs = Bidirectional(LSTM(LSTM_SIZE, return_sequences=True, activation='relu'))(inputs)\n",
    "outputs = Bidirectional(LSTM(LSTM_SIZE, return_sequences=True, activation='relu'))(outputs)\n",
    "outputs = Bidirectional(LSTM(LSTM_SIZE, return_sequences=False, activation='relu'))(outputs)\n",
    "predictions = Dense(n_features, activation='linear')(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:-SPLIT], X[-SPLIT:]\n",
    "y_train, y_test = y[:-SPLIT], y[-SPLIT:]\n",
    "\n",
    "print(\"X_train:\",X_train.shape,\"; X_test:\", X_test.shape)\n",
    "print(\"y_train:\",y_train.shape,\"   ; y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:59:43.218363Z",
     "start_time": "2020-04-27T06:59:19.640984Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_and_fit(inputs, predictions, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Evaluate the prediction.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the prediction (To be completed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Multi-Step LSTM Models\n",
    "\n",
    "A time series forecasting problem that requires a prediction of multiple time steps into the future can be referred to as multi-step time series forecasting. Specifically, these are problems where the forecast horizon or interval is more than one time step. There are two main types of LSTM models that can be used for multi-step forecasting; they are:\n",
    "\n",
    "1. Vector Output Model\n",
    "1. Encoder-Decoder Model\n",
    "\n",
    "### Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:59:43.227689Z",
     "start_time": "2020-04-27T06:59:43.220483Z"
    }
   },
   "outputs": [],
   "source": [
    "time_series = [fct(x) for x in range(SIZE)]\n",
    "\n",
    "n_in, n_out = 3, 2\n",
    "X, y = convert_data_univariate(time_series, n_in, n_out)\n",
    "\n",
    "# Summarize the data\n",
    "for i in range(3):\n",
    "    print(\"-\"*15)\n",
    "    print(\"X:\", X[i])\n",
    "    print(\"y:\", y[i])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like other types of neural network models, the LSTM can output a vector directly that can be interpreted as a multi-step forecast. This approach was seen in the previous section were one time step of each output time series was forecasted as a vector.\n",
    "\n",
    "As with the LSTMs for univariate data in a prior section, the prepared samples must first be reshaped. The LSTM expects data to have a three-dimensional structure of `[samples, timesteps, features]`, and in this case, we only have one feature so the reshape is straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:59:43.232655Z",
     "start_time": "2020-04-27T06:59:43.229496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1 # stand for uni-variate time series\n",
    "\n",
    "X_train = X.reshape((X.shape[0], X.shape[1], n_features))[:-SPLIT]\n",
    "X_test = X.reshape((X.shape[0], X.shape[1], n_features))[-SPLIT:]\n",
    "\n",
    "y_train, y_test = y[:-SPLIT], y[-SPLIT:]\n",
    "\n",
    "print(\"X_train:\",X_train.shape,\"; X_test:\", X_test.shape)\n",
    "print(\"y_train:\",y_train.shape,\"   ; y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector-Output Model\n",
    "\n",
    "Any of the presented Bi-LSTM model types could be used, such as Vanilla, Stacked, Bidirectional, CNN-LSTM, or ConvLSTM. Below defines a Stacked LSTM for multi-step forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T06:59:43.767449Z",
     "start_time": "2020-04-27T06:59:43.234246Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(n_in, n_features))\n",
    "outputs = Bidirectional(LSTM(LSTM_SIZE, return_sequences=True, activation='relu'))(inputs)\n",
    "outputs = Bidirectional(LSTM(LSTM_SIZE, return_sequences=True, activation='relu'))(outputs)\n",
    "outputs = Bidirectional(LSTM(LSTM_SIZE, return_sequences=False, activation='relu'))(outputs)\n",
    "predictions = Dense(n_out, activation='linear')(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:00:13.136819Z",
     "start_time": "2020-04-27T06:59:43.768851Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_and_fit(inputs, predictions, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Evaluate the prediction.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the prediction (To be completed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder Model <span style=\"color:purple\">(To Go Further)</span>\n",
    "\n",
    "It's a model specifically developed for forecasting variable length output sequence. The model was designed for prediction problems where there are both input and output sequences, so-called sequence-to-sequence, or seq2seq problems, such as translating text from one language to another. As its name suggests, the model is comprised of two sub-models: the encoder and the decoder.\n",
    "\n",
    "The encoder is a model responsible for reading and interpreting the input sequence. The output of the encoder is a fixed length vector that represents the model’s interpretation of the sequence. The encoder is traditionally a Vanilla LSTM model, although other encoder models can be used such as Stacked, Bidirectional, and CNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:00:13.140804Z",
     "start_time": "2020-04-27T07:00:13.138743Z"
    }
   },
   "outputs": [],
   "source": [
    "n_features = 1 # stand for uni-variate time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:00:13.703415Z",
     "start_time": "2020-04-27T07:00:13.142464Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encoder part\n",
    "inputs = Input(shape=(n_in, n_features))\n",
    "outputs = Bidirectional(LSTM(LSTM_SIZE, return_sequences=True, activation='relu'))(inputs)\n",
    "outputs = Bidirectional(LSTM(LSTM_SIZE, return_sequences=True, activation='relu'))(outputs)\n",
    "encoded = Bidirectional(LSTM(LSTM_SIZE, return_sequences=False, activation='relu'))(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder uses the output of the encoder as an input.\n",
    "\n",
    "* First, the fixed-length output of the encoder is repeated, once for each required time step in the output sequence.\n",
    "* Then, this sequence is then provided to an LSTM decoder model. The model must output a value for each value in the output time step, which can be interpreted by a single output model.\n",
    "* Then, we can use the same output layer or layers to make each one-step prediction in the output sequence. This can be achieved by wrapping the output part of the model in a TimeDistributed wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:00:13.816390Z",
     "start_time": "2020-04-27T07:00:13.705671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decoder part\n",
    "from keras.layers import RepeatVector\n",
    "\n",
    "outputs = RepeatVector(n_out)(encoded)\n",
    "outputs = LSTM(LSTM_SIZE, activation='relu', return_sequences=True)(outputs)\n",
    "predictions = TimeDistributed(Dense(1))(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:00:18.711668Z",
     "start_time": "2020-04-27T07:00:18.706774Z"
    }
   },
   "outputs": [],
   "source": [
    "# reshape input data from [samples, timesteps] into [samples, timesteps, features]\n",
    "X_train = X.reshape((X.shape[0], X.shape[1], n_features))[:-SPLIT]\n",
    "X_test = X.reshape((X.shape[0], X.shape[1], n_features))[-SPLIT:]\n",
    "\n",
    "# reshape output data from [samples, timesteps] into [samples, timesteps, features]\n",
    "y_train = y.reshape((y.shape[0], y.shape[1], n_features))[:-SPLIT]\n",
    "y_test = y.reshape((y.shape[0], y.shape[1], n_features))[-SPLIT:]\n",
    "\n",
    "print(\"X_train:\",X_train.shape,\"; X_test:\", X_test.shape)\n",
    "print(\"y_train:\",y_train.shape,\"   ; y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:00:58.335964Z",
     "start_time": "2020-04-27T07:00:19.807726Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_and_fit(inputs, predictions, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Parallel Input and Multi-Step Output <span style=\"color:purple\">(To Go Further)</span>\n",
    "\n",
    "A problem with parallel time series may require the prediction of multiple time steps of each time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:02:31.403290Z",
     "start_time": "2020-04-27T07:02:31.395537Z"
    }
   },
   "outputs": [],
   "source": [
    "n_in, n_out = 6, 2\n",
    "\n",
    "X, y = convert_data_multiplesparallelseries(dataset, n_in, n_out)\n",
    "n_features = X.shape[-1] # in order to capture the multi-variate dimension\n",
    "\n",
    "# Summarize the data\n",
    "for i in range(3):\n",
    "    print(\"-\"*15)\n",
    "    print(\"X:\", X[i])\n",
    "    print(\"y:\", y[i])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T09:33:12.718592Z",
     "start_time": "2020-04-21T09:33:12.715262Z"
    }
   },
   "source": [
    "We can use either the Vector Output or Encoder-Decoder LSTM to model this problem. In this case, we will use the Encoder-Decoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:02:33.024823Z",
     "start_time": "2020-04-27T07:02:32.465864Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encoder part\n",
    "inputs = Input(shape=(n_in, n_features))\n",
    "outputs = Bidirectional(LSTM(LSTM_SIZE, return_sequences=True, activation='relu'))(inputs)\n",
    "outputs = Bidirectional(LSTM(LSTM_SIZE, return_sequences=True, activation='relu'))(outputs)\n",
    "encoded = Bidirectional(LSTM(LSTM_SIZE, return_sequences=False, activation='relu'))(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:02:33.134442Z",
     "start_time": "2020-04-27T07:02:33.026441Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decoder part\n",
    "from keras.layers import RepeatVector\n",
    "\n",
    "outputs = RepeatVector(n_out)(encoded)\n",
    "outputs = LSTM(LSTM_SIZE, activation='relu', return_sequences=True)(outputs)\n",
    "predictions = TimeDistributed(Dense(n_features))(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:02:33.243542Z",
     "start_time": "2020-04-27T07:02:33.239242Z"
    }
   },
   "outputs": [],
   "source": [
    "# reshape input data from [samples, timesteps] into [samples, timesteps, features]\n",
    "X_train = X.reshape((X.shape[0], X.shape[1], n_features))[:-SPLIT]\n",
    "X_test = X.reshape((X.shape[0], X.shape[1], n_features))[-SPLIT:]\n",
    "\n",
    "# reshape output data from [samples, timesteps] into [samples, timesteps, features]\n",
    "y_train = y.reshape((y.shape[0], y.shape[1], n_features))[:-SPLIT]\n",
    "y_test = y.reshape((y.shape[0], y.shape[1], n_features))[-SPLIT:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:03:21.848126Z",
     "start_time": "2020-04-27T07:02:33.666691Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_and_fit(inputs, predictions, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## <span style=\"color:purple\">**Your Turn:** The `covid19` Dataset</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Confirmed Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fatalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multistep Univariate Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirmed Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fatalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multistep Multivariate Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
