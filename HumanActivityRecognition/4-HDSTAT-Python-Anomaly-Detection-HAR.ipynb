{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  [Apprentissage en Grande Dimension](https://github.com/wikistat/High-Dimensional-Learning ):  [Reconnaissance d'Activité Humaine](https://github.com/wikistat/High-Dimensional-Statistics/tree/master/HumanActivityRecognition) ([*HAR*](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)) en <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 120px; display: inline\" alt=\"Python\"/></a>    Detection d'anomalies\n",
    "\n",
    "## 1.1 Contexte\n",
    "Les données sont issues de la communauté qui vise la reconnaissance d'activités humaines (*Human activity recognition, HAR*) à partir d’enregistrements, par exemple du gyroscope et de l'accéléromètre d'un smartphone, objet connecté précurseur et dont la fonctionnalité de téléphonie devient très secondaire.\n",
    "Voir à ce propos l'[article](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-11.pdf) relatant un colloque de 2013.  \n",
    "\n",
    "Les données publiques disponibles et largement étudiées ont été acquises, décrites et analysées par [Anguita et al. (2013)]().\n",
    "Elles sont accessibles sur le [dépôt](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) de l'University California Irvine (UCI) consacré à l'apprentissage machine ainsi que sur le site *Kaggle*.\n",
    "\n",
    "L'archive contient les données brutes: accélérations en x, y, et z, chacun de 128 colonnes. D'autres fichiers en y soustrayant la gravité naturelle ainsi que les accélérations angulaires en x, y, et z soit en tout 9 fichiers. Mais 6 utiles avec 6*128=768 mesures.\n",
    "\n",
    "\n",
    "Ce notebook présente la partie détection d'anomalies sur les données métiers et sur les brutes. \n",
    "\n",
    "## 1.2 Objectifs : \n",
    "\n",
    "-Appliquer différentes méthodes de détection d'anomalies sur des données vectorielles (données métiers): \n",
    "\n",
    "  - Classification ascendante hiérarchique\n",
    "  - One-class SVM\n",
    "  - Local Outlier Factor\n",
    "  - Isolation Forest\n",
    " \n",
    "-Détection d'anomalies sur des données fonctionnelles : transformation des données fonctionnelles afin de définir des caractéristiques (ACP, transformation en ondelettes, FFT) sur lesquelles on applique les méthodes de détection d'anomalies \n",
    "\n",
    "-Comparaison des différentes méthodes  sur les données HAR. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Téléchargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ACP\n",
    "import sklearn.decomposition as sd\n",
    "import sklearn.preprocessing as sp\n",
    "\n",
    "# Hierarchical clustering\n",
    "import scipy.cluster.hierarchy as sch\n",
    "# LOF\n",
    "import sklearn.neighbors as sn\n",
    "# Isolation Forest\n",
    "import sklearn.ensemble as se\n",
    "\n",
    "# Plot et Display\n",
    "import utils.illustration as uil\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set()\n",
    "sb.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIGNALS = [ \"body_acc_x\", \"body_acc_y\", \"body_acc_z\", \"body_gyro_x\", \"body_gyro_y\", \"body_gyro_z\"]\n",
    "CMAP = plt.get_cmap(\"Set1\")\n",
    "ACTIVITY_DIC = {1 : \"WALKING\",\n",
    "2 : \"WALKING UPSTAIRS\",\n",
    "3 : \"WALKING DOWNSTAIRS\",\n",
    "4 : \"SITTING\",\n",
    "5 : \"STANDING\",\n",
    "6 : \"LAYING\"}\n",
    "COLOR_DIC = {v:CMAP(k-2) if v!=\"WALKING\" else CMAP(10) for k,v in ACTIVITY_DIC.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Les données\n",
    "### 2.2.1 Téléchargement des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils.load as ul\n",
    "\n",
    "#Multidimensional Data\n",
    "X_train = ul.load_signals(\"train\", SIGNALS)\n",
    "Y_train_label = ul.load_y(\"train\")\n",
    "X_train_metier= ul.my_read_csv(\"train/X_train.txt\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Constitution des jeux de données avec anomalies\n",
    "\n",
    "On construit un jeu de données constitué de \n",
    "\n",
    "   * `N_normal` signaux considérés comme normaux (associés au comportement *WALKING*).  \n",
    "   * `N_anormal` signaux par type de signaux anormaux (*WALKING UPSTAIRS*, WALKING DOWNSTAIRS*, *SITTING*, *STANDING*, *LAYING*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "N_normal = 800\n",
    "N_anormal = 2\n",
    "\n",
    "# New Y Label\n",
    "Y= np.hstack([np.repeat(1,N_normal)] + [np.repeat(i, N_anormal) for i in range(2,7)])\n",
    "Y_label = np.array([ACTIVITY_DIC[y] for y in Y])\n",
    "#New X Data\n",
    "index_per_act = np.hstack([np.where(Y_train_label==1)[0][:N_normal]] + [np.where(Y_train_label==act)[0][:N_anormal] for act in range(2,7)])\n",
    "\n",
    "X = X_train[index_per_act]\n",
    "X_metier = X_train_metier[index_per_act]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque type de signal, on affiche un echantillon des comportement normaux, ainsi que les différentes anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_sample_per_activity = dict([(v,50) if v==\"WALKING\" else (v,N_anormal) for k,v in ACTIVITY_DIC.items()])\n",
    "linestyle_per_activity = dict([(v,\"dashed\") if v==\"WALKING\" else (v,\"solid\") for k,v in ACTIVITY_DIC.items()])\n",
    "linewidth_per_activity = dict([(v,1) if v==\"WALKING\" else (v,2) for k,v in ACTIVITY_DIC.items()])\n",
    "\n",
    "fig = plt.figure(figsize=(16,18))    \n",
    "uil.plot_signaux(fig, X, Y_label, SIGNALS, COLOR_DIC, nb_sample_per_activity, \n",
    "             linestyle_per_activity, linewidth_per_activity, figdim1 = 3, figdim2 = 2, legend=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Analyse en composantes principales\n",
    "### 2.3.1  Sur un signal : l'accélération en x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isignal = 0\n",
    "print(\"ACP on signal \" + SIGNALS[isignal])\n",
    "X_signal = np.vstack([x[:,isignal] for x in X])\n",
    "\n",
    "acp = sd.PCA()\n",
    "X_acp_signal = acp.fit_transform(sp.scale(X_signal))\n",
    "\n",
    "X_signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = X.shape[0]\n",
    "colors=[COLOR_DIC[y] for y in Y_label]\n",
    "markersizes = [60 if y==1 else 140 for y in Y]\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_signal, acp, colors=colors, markersizes = markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q* Commenter les résultats dans la perpective de la détection d'anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2  Sur tous les signaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_signaux = np.vstack([x.reshape(128*6) for x in X])\n",
    "acp = sd.PCA()\n",
    "X_acp_signaux = acp.fit_transform(sp.scale(X_signaux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_signaux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_signaux, acp, colors, markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Sur les données métiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acp = sd.PCA()\n",
    "X_acp_metier = acp.fit_transform(sp.scale(X_metier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_metier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_metier, acp, colors, markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q* Commenter les résultats dans la perpective de la détection d'anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Détection d'anomalies sur les données \"métiers\"\n",
    "\n",
    "Il semble assez aisé de détecter les anomalies sur les données \"métiers\". Nous appliquons les méthodes classique : Classification ascendante hiérarchqie avec l'option \"single\", One class SVM, Local Outlier Factor et Isolation Forest. \n",
    "Les différentes méthodes n'ont pas nécessairement été optimisées. Etudiez  l'impact des différents paramètres sur la détection d'anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Classification Ascendante Hiérarchique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sch.linkage(X_metier, 'single')\n",
    "C = np.array([c[0] for c in sch.cut_tree(Z,6)])\n",
    "\n",
    "CT_HCA = pd.DataFrame(list(zip(C,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_HCA.pred, CT_HCA.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"\" if y==\"WALKING\" else y for y in Y_label]\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "sch.dendrogram( Z, p=6, leaf_rotation=45.,leaf_font_size=15,labels=LABELS, truncate_mode=\"level\"  # font size for the x axis labels\n",
    ")\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "\n",
    "ax =fig.get_axes()[0]\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    if lbl.get_text() in COLOR_DIC:\n",
    "        lbl.set_color(COLOR_DIC[lbl.get_text()])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2  One class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.05)\n",
    "\n",
    "OCS.fit(X_metier)\n",
    "pred = OCS.predict(X_metier)\n",
    "\n",
    "CT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_svm.pred, CT_svm.Anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_svm,COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination=0.05\n",
    "metric = \"euclidean\"\n",
    "n_neighbors = 15\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric)\n",
    "y_pred = clf.fit_predict(X_metier)\n",
    "\n",
    "CT_metier_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_metier_lof.pred, CT_metier_lof.Anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_metier_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = se.IsolationForest(n_estimators=100, contamination=0.05, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_metier)\n",
    "y_pred = clf.predict(X_metier)\n",
    "\n",
    "CT_IF = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_IF.pred, CT_IF.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_IF, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q. ** Quelle est votre conclusion sur les données métier ? \n",
    "\n",
    "L'objectif de la section suivante est d'essayer de détecter les anomalies sur les données  brutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Détection d'anomalies sur les signaux "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Classification Ascendante Hiérarchique\n",
    "\n",
    "On travaille tout d'abord sur un signal : l'accélération en x. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sch.linkage(X_signal,'single')\n",
    "\n",
    "C = np.array([c[0] for c in sch.cut_tree(Z,6)])\n",
    "\n",
    "CT_HCA = pd.DataFrame(list(zip(C,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_HCA.pred, CT_HCA.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"\" if y==\"WALKING\" else y for y in Y_label]\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "sch.dendrogram( Z, p=6, leaf_rotation=45.,leaf_font_size=15,labels=LABELS, truncate_mode=\"level\"  # font size for the x axis labels\n",
    ")\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "\n",
    "ax =fig.get_axes()[0]\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    if lbl.get_text() in COLOR_DIC:\n",
    "        lbl.set_color(COLOR_DIC[lbl.get_text()])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Combien d anomalies a-t-on détecté ? Obtient-on de meilleurs résultats en prenant tous les signaux ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 One class SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Sur les deux premières composantes de l'ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.01)\n",
    "\n",
    "OCS.fit(X_acp_signal[:,:2])\n",
    "pred = OCS.predict(X_acp_signal[:,:2])\n",
    "\n",
    "CT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_svm.pred, CT_svm.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Commentez les résultats. Obtient-on de meilleurs résultats en augmentant le nombre de composantes ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acp = X_acp_signal\n",
    "nu = 0.02\n",
    "\n",
    "# fit the model\n",
    "clf = ssvm.OneClassSVM(kernel=\"rbf\",nu=nu)\n",
    "clf.fit(X_acp[:,:2])\n",
    "y_pred_train = clf.predict(X_acp[:,:2])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "markersizes = [10 if y==1 else 20 for y in Y]\n",
    "labels = [\"\"] * N \n",
    "for il, l in [(np.where(Y_label==y)[0][0],y) for y in set(Y_label)]:\n",
    "    labels[il] = l\n",
    "\n",
    "uil.plot_decision_function(fig, ax, clf, X_acp, y_pred_train, colors=colors, labels = labels, markersizes=markersizes)\n",
    "ax.set_title(\"Novelty Detection : nu=%.1f\" %nu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_svm, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Sur l'accélération en x :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.05)\n",
    "\n",
    "OCS.fit(X_signal)\n",
    "pred = OCS.predict(X_signal)\n",
    "\n",
    "CT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_svm.pred, CT_svm.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Commenter les résultats. L'application de la méthode sur tous les signaux améliore-t-elle les résultats ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Local Outlier Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Sur l'accélération en x : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contamination=0.05\n",
    "metric = \"euclidean\"\n",
    "n_neighbors = 15\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric)\n",
    "y_pred = clf.fit_predict(X_signal)\n",
    "\n",
    "CT_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_lof.pred, CT_lof.Anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination=0.05\n",
    "metric = \"euclidean\"\n",
    "n_neighbors = 15\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric)\n",
    "y_pred = clf.fit_predict(X_signaux)\n",
    "\n",
    "CT_tous_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_tous_lof.pred, CT_tous_lof.Anomaly))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Commenter les résultats. Obtient-on de meilleures performances sur l'ensemble des signaux ? En modifiant les paramètres ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Sur les composantes de l'ACP : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acp = X_acp_signal\n",
    "n_neighbors = 15\n",
    "\n",
    "# fit the model\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric = metric)\n",
    "y_pred = clf.fit_predict(X_acp[:,:2])\n",
    "\n",
    "CT_ACP_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_lof.pred, CT_ACP_lof.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_decision_function(fig, ax, clf, X_acp, y_pred, method_name=\"LOF\", colors=colors, labels = labels, markersizes=markersizes)\n",
    "ax.set_title(\"Number of neighbors : %d\" %n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 Sur l'accélération en x :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = se.IsolationForest(n_estimators=100, contamination=0.05, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "#clf.fit(X_acp_metier)\n",
    "#y_pred = clf.predict(X_acp_metier)\n",
    "\n",
    "clf.fit(X_signal)\n",
    "y_pred = clf.predict(X_signaux)\n",
    "\n",
    "CT_IF = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_IF.pred, CT_IF.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_IF, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 Sur les composantes de l'ACP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acp = X_acp_signal\n",
    "\n",
    "contamination=0.05\n",
    "clf = se.IsolationForest(n_estimators=100, contamination=contamination, bootstrap=True, n_jobs=-1)\n",
    "clf.fit(X_acp[:,:2])\n",
    "y_pred = clf.predict(X_acp[:,:2])\n",
    "\n",
    "CT_IF = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_IF.pred, CT_IF.Anomaly))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Obtient-on de meilleurs résultats en augmentant le nombre de composantes de l'ACP ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En conclusion, les méthodes de détection d'anomalies appliquées directement sur les signaux ne fonctionnent pas bien. Nous allons voir si la projection sur une base d'ondelettes permet d'obtenir de meilleurs résultats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Détection d'anomalies sur la décomposition en ondelettes  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5.1 Décomposition en ondelettes\n",
    "\n",
    "On travaille sur l'accélération en x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "from pywt import wavedec\n",
    "\n",
    "from statsmodels.robust import mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isignal = 0\n",
    "print(\" signal \" + SIGNALS[isignal])\n",
    "X_signal = np.vstack([x[:,isignal] for x in X])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wf = \"haar\"\n",
    "\n",
    "Coeff = []\n",
    "TCoeff = []\n",
    "for x in X_signal :\n",
    "    #Apply wavelet decomposition\n",
    "    coeffs = pywt.wavedec(x,wf,level=7)\n",
    "    coeffs_flatten = np.hstack(coeffs)\n",
    "    Coeff.append(coeffs_flatten)\n",
    "    \n",
    "    # Compute universal Threshold http://jseabold.net/blog/2012/02/23/wavelet-regression-in-python/\n",
    "    sigma = mad(coeffs[-1])\n",
    "    uthresh = sigma*np.sqrt(2*np.log(128))\n",
    "    # Apply Threshold on 4 last levels\n",
    "    coeffs_thresh = [pywt.threshold(c, uthresh, mode=\"hard\") if i<=3 else c for i,c in enumerate(coeffs[::-1])]\n",
    "    coeffs_thresh_flatten = np.hstack(coeffs_thresh[::-1])\n",
    "    TCoeff.append(coeffs_thresh_flatten)\n",
    "    \n",
    "Coeff = np.array(Coeff)\n",
    "TCoeff = np.array(TCoeff)\n",
    "print(Coeff.shape, TCoeff.shape)\n",
    "print(np.sum(Coeff!=0), np.sum(TCoeff!=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On conserve seulement les coefficients de niveau 1 à 4, les autres sont considérés comme du bruit et annulés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Coefficient de niveau 1 à 4 : \n",
    "CoeffA4=Coeff[:,:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 ACP des coefficients d'ondelettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acp = sd.PCA()\n",
    "X_acp_ond = acp.fit_transform(sp.scale(Coeff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_ond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markersizes = [60 if y==1 else 140 for y in Y]\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_ond, acp, colors, markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 ACP des coefficients d'ondelettes de niveau 1 à 4 :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acp = sd.PCA()\n",
    "X_acp_ondA4 = acp.fit_transform(sp.scale(CoeffA4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_ondA4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markersizes = [60 if y==1 else 140 for y in Y]\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_ondA4, acp, colors, markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q* Commenter ces résultats en vue de la détection d'anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Classification ascendante hiérarchique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sch.linkage(Coeff, 'single')\n",
    "C = np.array([c[0] for c in sch.cut_tree(Z,6)])\n",
    "\n",
    "CT_HCA = pd.DataFrame(list(zip(C,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_HCA.pred, CT_HCA.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"\" if y==\"WALKING\" else y for y in Y_label]\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "sch.dendrogram( Z, p=6, leaf_rotation=45.,leaf_font_size=15,labels=LABELS, truncate_mode=\"level\"  # font size for the x axis labels\n",
    ")\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "\n",
    "ax =fig.get_axes()[0]\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    if lbl.get_text() in COLOR_DIC:\n",
    "        lbl.set_color(COLOR_DIC[lbl.get_text()])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 One class SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.1 Sur tous les coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.05)\n",
    "\n",
    "OCS.fit(Coeff)\n",
    "pred = OCS.predict(Coeff)\n",
    "\n",
    "CT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_svm.pred, CT_svm.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Obtient-on de meilleurs résultats avec les coefficients seuillés ? Avec les coefficients de niveau 1 à 4 ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Local Outlier Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.1 Sur  les coefficients de niveaux 1 à 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination=0.05\n",
    "metric = \"euclidean\"\n",
    "n_neighbors = 15\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric)\n",
    "y_pred = clf.fit_predict(CoeffA4)\n",
    "\n",
    "CT_ond_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_ond_lof.pred, CT_ond_lof.Anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_ond_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Obtient-on de meilleurs résultats avec les tous les coefficients ? avec les coefficients seuillés ? Avec les coefficients de niveau  plus élevé ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.1 Sur tous les coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = se.IsolationForest(n_estimators=100, contamination=0.05, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "clf.fit(Coeff)\n",
    "y_pred = clf.predict(Coeff)\n",
    "\n",
    "CT_IF = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_IF.pred, CT_IF.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Obtient-on de meilleurs résultats avec les coefficients seuillés ? Avec les coefficients de niveau 1 à 4 ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Nous avons travaillé seulement sur l'accélération en x.  Considérer l'ensemble des signaux améliore-t-il les résultats ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion :** Les méthodes de détection d'anomalies considérées appliquées sur  signaux bruts, comme les coefficinets d'ondelettes ne permettent pas de détecter les signaux atypiques. \n",
    "Nous allons utiliser la transformée de Fourier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Détection d'anomalies sur les coefficients de la FFT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients fft : \n",
    "\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "isignal = 0\n",
    "print(\" signal \" + SIGNALS[isignal])\n",
    "X_signal = np.vstack([x[:,isignal] for x in X])\n",
    "\n",
    "#print(amplitudefft)\n",
    "#plt.plot(amplitudefft)\n",
    "\n",
    "fftCoeff = []\n",
    "\n",
    "for x in X_signal :\n",
    "    \n",
    "    mx=np.mean(x)\n",
    "    x_centre=x-mx\n",
    "   #Apply fast Fourier transform\n",
    "    coeffsfft=np.abs(fft(x_centre))  \n",
    "    coeffsfft_flatten = np.hstack(coeffsfft)\n",
    "    fftCoeff.append(coeffsfft_flatten)\n",
    "        \n",
    "fftCoeff = np.array(fftCoeff)\n",
    "\n",
    "# Il suffit de garder la moitié des coefficients (ils sont ensuite répétés  de manière symétrique)\n",
    "\n",
    "fftCoeff=fftCoeff[:,:64]\n",
    "print(fftCoeff.shape)\n",
    "print(np.sum(fftCoeff!=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 ACP des coefficients FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acp = sd.PCA()\n",
    "X_acp_fft = acp.fit_transform(sp.scale(fftCoeff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_fft, acp, colors, markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q* Quels signaux se distinguent bien des autres ? Est-ce cohérent avec ce qui a été vu dans les calepins précédents ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Classification ascendante hiérarchique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sch.linkage(fftCoeff, 'single')\n",
    "C = np.array([c[0] for c in sch.cut_tree(Z,6)])\n",
    "\n",
    "CT_HCA = pd.DataFrame(list(zip(C,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_HCA.pred, CT_HCA.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"\" if y==\"WALKING\" else y for y in Y_label]\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "sch.dendrogram( Z, p=6, leaf_rotation=45.,leaf_font_size=15,labels=LABELS, truncate_mode=\"level\"  # font size for the x axis labels\n",
    ")\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "\n",
    "ax =fig.get_axes()[0]\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    if lbl.get_text() in COLOR_DIC:\n",
    "        lbl.set_color(COLOR_DIC[lbl.get_text()])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Commentez les résultats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 One class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.05)\n",
    "\n",
    "OCS.fit(fftCoeff)\n",
    "pred = OCS.predict(fftCoeff)\n",
    "\n",
    "CT_FFT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_FFT_svm.pred, CT_FFT_svm.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Etudiez l'impact du noyau et du paramètre nu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination=0.05\n",
    "metric = \"euclidean\"\n",
    "n_neighbors = 15\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric)\n",
    "y_pred = clf.fit_predict(fftCoeff)\n",
    "\n",
    "CT_FFT_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_FFT_lof.pred, CT_FFT_lof.Anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_FFT_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q** Commentez les résultats et regardez l'impact des paramètre. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = se.IsolationForest(n_estimators=100, contamination=0.05, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "clf.fit(fftCoeff)\n",
    "y_pred = clf.predict(fftCoeff)\n",
    "\n",
    "CT_IF = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_IF.pred, CT_IF.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 6.6 Visualisation des résultats de LOF \n",
    "\n",
    "La méthode LOF est l'une des plus performantes quelque soit le type de \"features\" considérées. On visualise les résultats de cette méthode pour les différents cas considérés dans le calepin. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40,40))\n",
    "ax = fig.add_subplot(3,2,1)\n",
    "uil.plot_detection_result(fig, ax, CT_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"Donnees Brutes- Boddy acc x \", fontsize=25)\n",
    "ax = fig.add_subplot(3,2,2)\n",
    "uil.plot_detection_result(fig, ax, CT_tous_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"Donnees Brutes- tous les signaux\", fontsize=25)\n",
    "ax = fig.add_subplot(3,2,3)\n",
    "uil.plot_detection_result(fig, ax, CT_ACP_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"ACP, 2 premieres composantes\", fontsize=25)\n",
    "ax = fig.add_subplot(3,2,4)\n",
    "uil.plot_detection_result(fig, ax, CT_ond_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"Ondelettes, coefficients niveaux 1 à 4 \", fontsize=25)\n",
    "ax = fig.add_subplot(3,2,5)\n",
    "uil.plot_detection_result(fig, ax, CT_metier_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"Données métiers\", fontsize=25)\n",
    "ax = fig.add_subplot(3,2,6)\n",
    "uil.plot_detection_result(fig, ax, CT_FFT_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"FFT\", fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 7. Conclusion\n",
    "\n",
    "Nous avons étudié diverses méthodes de détection d'anomalies. Sur les données \"métiers\", il est assez simple de détecter les données atypiques. Sur les données fonctionnelles, nous avons vu l'importance de définir de bons \"features\" pour mettre en lumière les anomalies : les méthodes de détection d'anomalies appliquées sur les signaux bruts ou leur transformée en ondelettes, n'ont certes pas été totalement optimisées mais  ne donnent pas de bons résultats dasn ce cas précis. Par contre, la transformée de Fourier rapide met bien en exergue les anomalies sur le cas de ces données. On ne peut pas en tirer de généralités : sur les données simulées de télémesures du calepin disponible  [ici](http://localhost:8888/notebooks/High-Dimensional-Learning/DonneesSimulees/HDSTAT-Python-Anomaly-Detection.ipynb), la transformation dans une base d'ondelettes est pertinente pour la détection d'anomalies dans les données fonctionnelles. Il est donc important de bien connaitre les données et le type d'anomaies que l'on souhaite détecter. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "592px",
    "left": "0px",
    "right": "957px",
    "top": "107px",
    "width": "259px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
