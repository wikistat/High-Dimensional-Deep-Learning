{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Dimensional & Deep Learning : Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  What is an Autoencoder ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P style=\"text-align:center\"><img src=\"https://blog.keras.io/img/ae/autoencoder_schema.jpg\" style=\"float:center; display: inline\" alt=\"schema\"/></P>\n",
    "<i>Architecture d'un autoencoder</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective \n",
    "\n",
    "During this TP  we will build different autoencoder with Keras and Tensorflow. Here are the main objective :\n",
    "\n",
    "* Build a autoencoder based on simple perceptron layer.\n",
    "* Add regularization one layer and understand their effect.\n",
    "* Build a convolutional autoencoder.\n",
    "* Use a convolutional autoencoder to solve denoising problem.\n",
    "* Manipulate the library in order to get and observe the result at different point of the dataflow.\n",
    "\n",
    "\n",
    "The dataset used all along with TP is the MNIST dataset.\n",
    "\n",
    "**EDIT**: 30/08/2019 Use Tensorflow V1 for this TP as Tensorflow V2 produce very unstable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.preprocessing.image as kpi\n",
    "import tensorflow.keras.models as km\n",
    "import tensorflow.keras.layers as kl\n",
    "import tensorflow.keras.regularizers as kr\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "As we won't apply any supervised algorithm in this TP, we do not need to load the `Y` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the previous TP, it is better to normalize the dataset before to apply algorithm on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "fig  = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "x = kpi.img_to_array(x_train[0])\n",
    "ax.imshow(x[:,:,0], interpolation='nearest', cmap=\"binary\")\n",
    "ax.grid(False)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple autoencoder\n",
    "\n",
    "We will first build a very simple architecture where :\n",
    "\n",
    "* the **encoder layer** : is a `Dense` layer composed of 32 neurons (the latent variable) with a `Relu` activation function :\n",
    "$$relu(x) = max(0,x)$$,\n",
    "* the **decoded layer** : is a `Dense` layer composed of  784 neurons (the input dimension) with a `Sigmoid`activation function.\n",
    "$$sigmoid(x) = \\frac{1}{1+\\text{e}^x}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first reshape the data from to be 1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flatten = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test_flatten = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "x_train_flatten.shape, x_test_flatten.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : write the simple model described above in keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent = 32\n",
    "n_input = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/simple_autoencoder.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then learn the model. Note that the target variable are the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train_flatten, x_train_flatten, epochs=50, batch_size=256, validation_data=(x_test_flatten, x_test_flatten))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : What can you say about the choosen loss function?  How is the loss evoluting during training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check outputs\n",
    "\n",
    "We will no check how the model performs. We produce first the encoded-decoded images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_test_imgs = autoencoder.predict(x_test_flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function display both the input and the output of the autoencoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(decoded_test_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : What can you say about this results?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Check latent variable\n",
    "\n",
    "The keras model that we have written above does not allow us to retrieve the latent variable. \n",
    "In order to do so, we have to re-write the model in order to get this variable late.\n",
    "\n",
    "We first write the encoder part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = km.Sequential(name=\"EncoderModel\")\n",
    "encoder.add(kl.Dense(n_latent, activation='relu', input_shape=(n_input,),name=\"encoder_layer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then write the decoder as  another independent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = km.Sequential(name=\"DecoderModel\")\n",
    "decoder.add(kl.Dense(n_input, activation='sigmoid', input_shape =(n_latent,), name = \"decoded_layer\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally writhe the autoencoder model by adding the two previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = km.Sequential(name=\"EncoderDecoder\")\n",
    "autoencoder.add(encoder)\n",
    "autoencoder.add(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is well composed of the association of the two previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can acces the two sub model with the following syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.get_layer(\"EncoderModel\").summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can then be learned the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train_flatten, x_train_flatten, epochs=50, batch_size=256, validation_data=(x_test_flatten, x_test_flatten))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What can you say about the loss value of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now access and produce easily the latent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_test_flatten)\n",
    "encoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display encoded imgs\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(encoded_imgs[i].reshape(8, 4))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can produce the decoded images by :\n",
    "* Using the decoded part on the encoded images.\n",
    "* Using the all architecture on the original image.\n",
    "\n",
    "**Exercise** : Ensure that both methods produce the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load solutions/decoded_images_both_method.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example the autoencoder is only constrained by the size of the hidden layer. \n",
    "\n",
    "In the following figure you can see the distribution of the number of latent variable set to zero for the 10.000 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(np.sum(encoded_imgs==0,axis=1), width=0.9, bins=np.arange(-0.5,10.5,1))\n",
    "ax.set_xticks(np.arange(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to get a sparser encoded representation of the images is to add a *sparsity contraint* on the activity function of the hidden layer. \n",
    "\n",
    "Regularizers enable to avoid overfitting by adding some constraint on the weight we want to control. \n",
    "\n",
    "Cost function = Loss (say, binary cross entropy) + Regularization term \n",
    "\n",
    "Cost function = Loss + $\\lambda$ $\\sum w$, where in our case $\\lambda = 10e-5$ and $w$ are the weight of the encoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 10e-5\n",
    "\n",
    "sparse_encoder = km.Sequential(name=\"SparseEncoderModel\")\n",
    "sparse_encoder.add(kl.Dense(n_latent, activation='relu', input_shape=(n_input,), activity_regularizer=kr.l1(l) ,name=\"encoder_layer\"))\n",
    "\n",
    "sparse_decoder = km.Sequential(name=\"SparseDecoderModel\")\n",
    "sparse_decoder.add(kl.Dense(n_input, activation='sigmoid', input_shape =(n_latent,), name = \"decoded_layer\" ))\n",
    "\n",
    "sparse_autoencoder = km.Sequential(name=\"SparseEncoderDecoder\")\n",
    "sparse_autoencoder.add(sparse_encoder)\n",
    "sparse_autoencoder.add(sparse_decoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can now train the model as previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "sparse_autoencoder.fit(x_train_flatten, x_train_flatten, epochs=50, batch_size=256,validation_data=(x_test_flatten, x_test_flatten))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : What can you say on the loss function compare to the previous model?\n",
    "\n",
    "**Exercise**  : Ensure that the encoded images obtained with the sparse autoencoder are indeed sparser than the ones obtain by the first autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/compare_sparsity_encoded_imgs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** : Compare the decoded images obtain by the first and the sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/compare_sparsity_decoded_imgs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous part, we have seen very simple autoencoder where both encoder and decoder part are composed of single layer. They both can be composed of more layers (deep autoencoder) and with differents types of layer.\n",
    "\n",
    "As seen in the previous TP, convolutional layers are the best layer to use when dealing with images. \n",
    "\n",
    "**Exercise** : Implement a convolutional Autoencoder with the folowwing architecture: \n",
    "\n",
    "conv_decoder = km.Sequential(name=\"ConvDecoderModel\")\n",
    "conv_decoder.add(kl.Conv2D(8, (3, 3), activation='relu', input_shape = conv_encoder.get_output_shape_at(-1)[-3:], padding='same'))\n",
    "conv_decoder.add(kl.UpSampling2D((2, 2)))\n",
    "conv_decoder.add(kl.Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "conv_decoder.add(kl.UpSampling2D((2, 2)))\n",
    "conv_decoder.add(kl.Conv2D(16, (3, 3), activation='relu'))\n",
    "conv_decoder.add(kl.UpSampling2D((2, 2)))\n",
    "conv_decoder.add(kl.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "`Encoder`\n",
    "* A 2d convolutional layer, 16 filters of size 3x3\n",
    "* A 2Dmaxpooling layer with filters of size 2x2\n",
    "* A 2d convolutial layer, 8 filters of size 3x3\n",
    "* A 2Dmaxpooling layer with filters of size 2x2\n",
    "* A 2d convolutial layer, 8 filters of size 3x3\n",
    "* A 2Dmaxpooling layer with filters of size 2x2\n",
    "\n",
    "`Decoder`\n",
    "* A 2d convolutional layer, 8 filters of size 3x3\n",
    "* A 2Dupsampling layer with filters of size 2x2\n",
    "* A 2d convolutional layer, 8 filters of size 3x3\n",
    "* A 2Dupsampling layer with filters of size 2x2\n",
    "* A 2d convolutional layer, 16 filters of size 3x3\n",
    "* A 2Dupsampling layer with filters of size 2x2\n",
    "* A 2d convolutional layer, 1 filters of size 3x3, with SIGMOID activation\n",
    "\n",
    "\n",
    "*All padding are `SAME` padding and all convolutional activation function but last are `RELU`*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/convolutional_autoencoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_autoencoder = km.Sequential(name=\"ConvAutoencoderModel\")\n",
    "conv_autoencoder.add(conv_encoder)\n",
    "conv_autoencoder.add(conv_decoder)\n",
    "conv_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "conv_autoencoder.fit(x_train_conv, x_train_conv, epochs=50, batch_size=256, validation_data=(x_test_conv, x_test_conv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What can you say about the loss function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = conv_encoder.predict(x_test_conv)\n",
    "decoded_imgs = conv_autoencoder.predict(x_test_conv)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n+1)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application to denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know how to build a convolutional autoencoder. \n",
    "\n",
    "We will now see how it can be used to solved denoising problem. \n",
    "\n",
    "We first create fake noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add random noise\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train_conv + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train_conv.shape) \n",
    "x_test_noisy = x_test_conv + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test_conv.shape) \n",
    "\n",
    "# Value greater than 1 are set to 1 and value lower than 0 are set to zero\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the noise we create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # noisy data\n",
    "    ax = plt.subplot(2, n, i + n+1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the same convolutional model that we built above. But let train this model with noisy data as an input and the original data as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_encoder = km.Sequential(name=\"ConvEncoderModel\")\n",
    "conv_encoder.add(kl.Conv2D(16, (3,3) , activation='relu', input_shape=(28,28,1) , padding='same' ))\n",
    "conv_encoder.add(kl.MaxPooling2D((2, 2), padding='same'))\n",
    "conv_encoder.add(kl.Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "conv_encoder.add(kl.MaxPooling2D((2, 2), padding='same'))\n",
    "conv_encoder.add(kl.Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "conv_encoder.add(kl. MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "conv_decoder = km.Sequential(name=\"ConvDecoderModel\")\n",
    "conv_decoder.add(kl.Conv2D(8, (3, 3), activation='relu', input_shape = conv_encoder.get_output_shape_at(-1)[-3:], padding='same'))\n",
    "conv_decoder.add(kl.UpSampling2D((2, 2)))\n",
    "conv_decoder.add(kl.Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "conv_decoder.add(kl.UpSampling2D((2, 2)))\n",
    "conv_decoder.add(kl.Conv2D(16, (3, 3), activation='relu'))\n",
    "conv_decoder.add(kl.UpSampling2D((2, 2)))\n",
    "conv_decoder.add(kl.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "conv_autoencoder = km.Sequential(name=\"ConvAutoencoderModel\")\n",
    "conv_autoencoder.add(conv_encoder)\n",
    "conv_autoencoder.add(conv_decoder)\n",
    "\n",
    "conv_autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "conv_autoencoder.fit(x_train_noisy, x_train_conv, epochs=10, batch_size=256, validation_data=(x_test_noisy, x_test_conv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we past the noisy test data into the trained autoencorder in order to denoise this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_denoised = conv_autoencoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results of the denoised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # noisy data\n",
    "    ax = plt.subplot(3, n, i + n+1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # denoised data\n",
    "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "    plt.imshow(x_test_denoised[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** : Play with different architecture to rease loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
